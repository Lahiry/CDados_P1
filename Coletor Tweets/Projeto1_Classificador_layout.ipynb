{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Projeto 1 - Ciência dos Dados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nome: Raphael Lahiry de Barros\n",
    "\n",
    "Nome: Florencia Averame Kramer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# O que temos que fazer?\n",
    "precisamos criar um dataframe para cada relevância   OK\n",
    "\n",
    "dentro desses dataframes separar as frases em palavras OK   \n",
    "\n",
    "analisar a freq relativa de cada palavra --> probabilidade daquela palavra pertencer àquela relevância    \n",
    "\n",
    "quando quisermos avaliar o teste--> analisamos a probabilidade de cada palavra de uma frase pertencer a uma relevância (usar o smoothing -- aula 8 -- para as palavras que talvez não existam em certas categorias)  \n",
    "\n",
    "com isso, para cada palavra teremos a probabilidade de que esta pertença a cada relevância  \n",
    "a relevância com maior probabilidade será a daquela palavra"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Atenção:** Serão permitidos grupos de três pessoas, mas com uma rubrica mais exigente. Grupos deste tamanho precisarão fazer um questionário de avaliação de trabalho em equipe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "## Carregando algumas bibliotecas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Em `filename`, coloque o nome do seu arquivo de dados!**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encontrei o arquivo ps4.xlsx, tudo certo para prosseguir com a prova!\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "filename = 'ps4.xlsx'\n",
    "if filename in os.listdir():\n",
    "    print(f'Encontrei o arquivo {filename}, tudo certo para prosseguir com a prova!')\n",
    "else:\n",
    "    print(f'Não encontrei o arquivo {filename} aqui no diretório {os.getcwd()}, será que você não baixou o arquivo?')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Carregando a base de dados com os tweets classificados como relevantes e não relevantes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Treinamento</th>\n",
       "      <th>Relevância</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>@odonodocabare_ comprei um tablet dia desses e...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>@encanadorchapad o negócio é o ps4 slim. peque...</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>rt @ps3brasil: tohu é anunciado para ps4; deta...</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>dividindo essa semana entre dois jogos no modo...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>@leobruto @fridaygus @douglasxavier8 @ocerveje...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         Treinamento  Relevância\n",
       "0  @odonodocabare_ comprei um tablet dia desses e...         0.0\n",
       "1  @encanadorchapad o negócio é o ps4 slim. peque...         4.0\n",
       "2  rt @ps3brasil: tohu é anunciado para ps4; deta...         2.0\n",
       "3  dividindo essa semana entre dois jogos no modo...         0.0\n",
       "4  @leobruto @fridaygus @douglasxavier8 @ocerveje...         0.0"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train = pd.read_excel(filename)\n",
    "train.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['Treinamento'] = train['Treinamento'].astype('str')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Teste</th>\n",
       "      <th>Relevância</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>@chaehobbit simmm sou apaixonada em jogos assi...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>@pimps_junin @joao_almirante atleta nato , pod...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>@isa_boechatt kkkk vc joga onde no xbox ps4 ou...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>@vezguu eu sou ps4</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>path of exile (ps4) - farmando e fazendo o atl...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Teste  Relevância\n",
       "0  @chaehobbit simmm sou apaixonada em jogos assi...         1.0\n",
       "1  @pimps_junin @joao_almirante atleta nato , pod...         1.0\n",
       "2  @isa_boechatt kkkk vc joga onde no xbox ps4 ou...         1.0\n",
       "3                                 @vezguu eu sou ps4         1.0\n",
       "4  path of exile (ps4) - farmando e fazendo o atl...         0.0"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = pd.read_excel(filename, sheet_name = 'Teste')\n",
    "test.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "test['Teste'] = test['Teste'].astype('str')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "## Classificador automático de sentimento\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Faça aqui uma descrição do seu produto e o que considerou como relevante ou não relevante na classificação dos tweets.\n",
    "\n",
    "Nosso produto é o playstation 4. Consideramos relevantes as mensagens que falavam sobre questões técnicas do produto e sobre satisfação, sejam positivas ou negativas. Consideramos irrelevantes as mensagens que só mencionavam o nosso produtos nas '#' ou que eram opiniões pessoais que não agregavam na nossa análise."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "## Montando um Classificador Naive-Bayes\n",
    "\n",
    "Considerando apenas as mensagens da planilha Treinamento, ensine  seu classificador."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "#função que apaga os caracteres especiais e as menções de usuários\n",
    "# https://docs.python.org/3/library/re.html#\n",
    "import re \n",
    "\n",
    "\n",
    "def cleanup(text):\n",
    "    \"\"\"\n",
    "        Função de limpeza muito simples que troca alguns sinais básicos por espaços\n",
    "    \"\"\"\n",
    "    #import string\n",
    "    punctuation = '[!-.:?;[]]' # Note que os sinais [] são delimitadores de um conjunto.\n",
    "    pattern = re.compile(punctuation)\n",
    "    text_subbed = re.sub(pattern, '', text)\n",
    "    \n",
    "    #filtro que remove as menções à usuários com @\n",
    "    filtro = filter(lambda x:x[0]!='@', text_subbed.split())\n",
    "    juncao = \" \".join(filter(lambda x:x[0]!='@', text_subbed.split()))\n",
    "    \n",
    "    return juncao\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "#aplicando a função cleanup na base treinamento e deixando tudo em letra minúscula\n",
    "train['Treinamento'] = train['Treinamento'].apply(cleanup)\n",
    "train['Treinamento'] = train['Treinamento'].str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['Relevância'] = train['Relevância'].astype('category')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      Muito irrelevante\n",
       "1        Muito relevante\n",
       "2                 Neutro\n",
       "3      Muito irrelevante\n",
       "4      Muito irrelevante\n",
       "             ...        \n",
       "746          Irrelevante\n",
       "747          Irrelevante\n",
       "748               Neutro\n",
       "749    Muito irrelevante\n",
       "750          Irrelevante\n",
       "Name: Relevância, Length: 751, dtype: category\n",
       "Categories (5, object): [Muito irrelevante < Irrelevante < Neutro < Relevante < Muito relevante]"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train['Relevância'].cat.categories = ['Muito irrelevante', 'Irrelevante', 'Neutro', 'Relevante', 'Muito relevante']\n",
    "train['Relevância'].cat.as_ordered()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ligando a relevância à um número\n",
    "muito_relevante = train['Relevância'] == 'Muito relevante'\n",
    "relevante = train['Relevância'] == 'Relevante'\n",
    "neutro = train['Relevância'] == 'Neutro'\n",
    "irrelevante = train['Relevância'] == 'Irrelevante'\n",
    "muito_irrelevante = train['Relevância'] == 'Muito irrelevante'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Treinamento</th>\n",
       "      <th>Relevância</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>comprei um tablet dia desses e to bem feliz......</td>\n",
       "      <td>Muito irrelevante</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>o negócio é o ps4 slim. pequeno e silencioso, ...</td>\n",
       "      <td>Muito relevante</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>rt tohu é anunciado para ps4; detalhes e gamep...</td>\n",
       "      <td>Neutro</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>dividindo essa semana entre dois jogos no modo...</td>\n",
       "      <td>Muito irrelevante</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>sentiu ? kkkkk. só fiz uma pergunta bem simple...</td>\n",
       "      <td>Muito irrelevante</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         Treinamento         Relevância\n",
       "0  comprei um tablet dia desses e to bem feliz......  Muito irrelevante\n",
       "1  o negócio é o ps4 slim. pequeno e silencioso, ...    Muito relevante\n",
       "2  rt tohu é anunciado para ps4; detalhes e gamep...             Neutro\n",
       "3  dividindo essa semana entre dois jogos no modo...  Muito irrelevante\n",
       "4  sentiu ? kkkkk. só fiz uma pergunta bem simple...  Muito irrelevante"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Filtros para criar os dataFrames com cada relevância"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_muito_relevante = train.loc[muito_relevante, :]\n",
    "df_relevante = train.loc[relevante, :]\n",
    "df_neutro = train.loc[neutro, :]\n",
    "df_irrelevante = train.loc[irrelevante, :]\n",
    "df_muito_irrelevante = train.loc[muito_irrelevante, :]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Separando cada coluna de relevância em listas de palavras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "palavras_muito_relevantes = []\n",
    "lista_vrw = []\n",
    "for vrw in df_muito_relevante['Treinamento']:\n",
    "    palavras_muito_relevantes.append(vrw.split(' '))\n",
    "for vrl in palavras_muito_relevantes:\n",
    "    lista_vrw += vrl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "palavras_relevantes = []\n",
    "lista_rw = []\n",
    "for rw in df_relevante['Treinamento']:\n",
    "    palavras_relevantes.append(rw.split(' '))\n",
    "for rl in palavras_relevantes:\n",
    "    lista_rw += rl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "palavras_neutras = []\n",
    "lista_nw = []\n",
    "for nw in df_neutro['Treinamento']:\n",
    "    palavras_neutras.append(nw.split(' '))\n",
    "for nl in palavras_neutras:\n",
    "    lista_nw += nl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "palavras_irrelevantes = []\n",
    "lista_iw = []\n",
    "for iw in df_irrelevante['Treinamento']:\n",
    "    palavras_irrelevantes.append(iw.split(' '))\n",
    "for il in palavras_irrelevantes:\n",
    "    lista_iw += il"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "palavras_muito_irrelevantes = []\n",
    "lista_viw = []\n",
    "for viw in df_muito_irrelevante['Treinamento']:\n",
    "    palavras_muito_irrelevantes.append(viw.split(' '))\n",
    "for vil in palavras_muito_irrelevantes:\n",
    "    lista_viw += vil"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transformando as listas de palavras de cada relevância em pd.Series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "serie_muito_relevante = pd.Series(lista_vrw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "serie_relevante = pd.Series(lista_rw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "serie_neutro = pd.Series(lista_nw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "serie_irrelevante = pd.Series(lista_iw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "serie_muito_irrelevante = pd.Series(lista_viw)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Frequências relativas e absolutas das palavras de cada relevância"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "freq_ab_muito_relevante = serie_muito_relevante.value_counts() \n",
    "freq_re_muito_relevante = serie_muito_relevante.value_counts(True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "freq_ab_relevante = serie_relevante.value_counts()\n",
    "freq_re_relevante = serie_relevante.value_counts(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "freq_ab_neutro = serie_neutro.value_counts()\n",
    "freq_re_neutro = serie_neutro.value_counts(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "freq_ab_irrelevante = serie_irrelevante.value_counts()\n",
    "freq_re_irrelevante = serie_irrelevante.value_counts(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "freq_ab_muito_irrelevante = serie_muito_irrelevante.value_counts()\n",
    "freq_re_muito_irrelevante = serie_muito_irrelevante.value_counts(True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Definindo a quantidade total de palavras na língua portuguesa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "#portugues são as palavras existes que a gente vai verificar a freq relativa e vamos somar um alpha pra garantir\n",
    "#que as palavras que não existem não zerem o classificador\n",
    "total_train = lista_vrw + lista_rw + lista_nw + lista_iw + lista_viw\n",
    "\n",
    "#na fórmula precisamos dividir pela quantidade de palavras na lingua portuguesa\n",
    "alpha = 1\n",
    "v = 1e6\n",
    "lingua_portuguesa = len(total_train) + alpha*v"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pd.series do português"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ps4        545\n",
       "o          463\n",
       "de         369\n",
       "e          359\n",
       "no         274\n",
       "          ... \n",
       "puder        1\n",
       "ps4\"         1\n",
       "sagrado      1\n",
       "2016         1\n",
       "5.k          1\n",
       "Length: 4270, dtype: int64"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "serie_total_train = pd.Series(total_train)\n",
    "serie_total_train.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Criando a probabilidade de cada relevância à priori"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n"
     ]
    }
   ],
   "source": [
    "p_mr = len(serie_muito_relevante)/len(serie_total_train)\n",
    "p_r = len(serie_relevante)/len(serie_total_train)\n",
    "p_n = len(serie_neutro)/len(serie_total_train)\n",
    "p_i = len(serie_irrelevante)/len(serie_total_train)\n",
    "p_mi = len(serie_muito_irrelevante)/len(serie_total_train)\n",
    "\n",
    "print(p_mr + p_r + p_n + p_i + p_mi)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Montando Naive-Bayes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classificador da relevância de cada palavra"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\n# lista muito relevante\\ndict_relevancia_palavras = {}\\n\\n\\nfor palavra in total_train:\\n    if (palavra not in lista_vrw) and (palavra not in lista_rw) and (palavra not in lista_nw) and (palavra not in lista_iw) and (palavra not in lista_viw):\\n        mr = alpha/len(total_train)\\n        r = alpha/len(total_train)\\n        n = alpha/len(total_train)\\n        i = alpha/len(total_train)\\n        mi = alpha/len(total_train)\\n        \\n    if palavra in lista_vrw:\\n        mr = freq_re_muito_relevante[palavra] \\n       \\n    if palavra in lista_rw:\\n        r = freq_re_relevante[palavra] \\n       \\n    if palavra in lista_nw:\\n        n = freq_re_neutro[palavra] \\n        \\n    if palavra in lista_iw:\\n        i = freq_re_irrelevante[palavra] \\n       \\n    if palavra in lista_viw:\\n        mi = freq_re_muito_irrelevante[palavra] \\n     \\n    if (mr > r) and (mr > n) and (mr > i) and (mr > mi):\\n        #print('mr')\\n        dict_relevancia_palavras[palavra] = 4\\n        #break\\n    elif (r > mr) and (r > n) and (r > i) and (r > mi):\\n        #print('r')\\n        dict_relevancia_palavras[palavra] = 3\\n        #break\\n    elif (n > mr) and (n > r) and (n > i) and (n > mi):\\n        #print('n')\\n        dict_relevancia_palavras[palavra] = 2\\n        #break\\n    elif (i > mr) and (i > r) and (i > n) and (i > mi):\\n        #print('i')\\n        dict_relevancia_palavras[palavra] = 1\\n        #break\\n    elif (mi > mr) and (mi > r) and (mi > n) and (mi > i):\\n        #print('mi')\\n        dict_relevancia_palavras[palavra] = 0\\n        #break\\n    \\n#dict_relevancia_palavras\\n\""
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "# lista muito relevante\n",
    "dict_relevancia_palavras = {}\n",
    "\n",
    "\n",
    "for palavra in total_train:\n",
    "    if (palavra not in lista_vrw) and (palavra not in lista_rw) and (palavra not in lista_nw) and (palavra not in lista_iw) and (palavra not in lista_viw):\n",
    "        mr = alpha/len(total_train)\n",
    "        r = alpha/len(total_train)\n",
    "        n = alpha/len(total_train)\n",
    "        i = alpha/len(total_train)\n",
    "        mi = alpha/len(total_train)\n",
    "        \n",
    "    if palavra in lista_vrw:\n",
    "        mr = freq_re_muito_relevante[palavra] \n",
    "       \n",
    "    if palavra in lista_rw:\n",
    "        r = freq_re_relevante[palavra] \n",
    "       \n",
    "    if palavra in lista_nw:\n",
    "        n = freq_re_neutro[palavra] \n",
    "        \n",
    "    if palavra in lista_iw:\n",
    "        i = freq_re_irrelevante[palavra] \n",
    "       \n",
    "    if palavra in lista_viw:\n",
    "        mi = freq_re_muito_irrelevante[palavra] \n",
    "     \n",
    "    if (mr > r) and (mr > n) and (mr > i) and (mr > mi):\n",
    "        #print('mr')\n",
    "        dict_relevancia_palavras[palavra] = 4\n",
    "        #break\n",
    "    elif (r > mr) and (r > n) and (r > i) and (r > mi):\n",
    "        #print('r')\n",
    "        dict_relevancia_palavras[palavra] = 3\n",
    "        #break\n",
    "    elif (n > mr) and (n > r) and (n > i) and (n > mi):\n",
    "        #print('n')\n",
    "        dict_relevancia_palavras[palavra] = 2\n",
    "        #break\n",
    "    elif (i > mr) and (i > r) and (i > n) and (i > mi):\n",
    "        #print('i')\n",
    "        dict_relevancia_palavras[palavra] = 1\n",
    "        #break\n",
    "    elif (mi > mr) and (mi > r) and (mi > n) and (mi > i):\n",
    "        #print('mi')\n",
    "        dict_relevancia_palavras[palavra] = 0\n",
    "        #break\n",
    "    \n",
    "#dict_relevancia_palavras\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lista muito relevante\n",
    "\n",
    "def classificador_relevancia(palavra):\n",
    "    dict_relevancia_palavras = {}\n",
    "    \n",
    "    if palavra not in total_train:\n",
    "        dict_relevancia_palavras[palavra] = alpha/lingua_portuguesa\n",
    "        print('NÂO EXISTIA DENTRO DE TRAIN')\n",
    "        \n",
    "    else:\n",
    "        print(\"ENTROU NO ELSE\")\n",
    "        for palavra in total_train:\n",
    "            \n",
    "            if palavra in lista_vrw:\n",
    "                mr = freq_re_muito_relevante[palavra]# + alpha\n",
    "\n",
    "            if palavra in lista_rw:\n",
    "                r = freq_re_relevante[palavra]# + alpha \n",
    "\n",
    "            if palavra in lista_nw:\n",
    "                n = freq_re_neutro[palavra]# + alpha \n",
    "\n",
    "            if palavra in lista_iw:\n",
    "                i = freq_re_irrelevante[palavra]# + alpha \n",
    "\n",
    "            if palavra in lista_viw:\n",
    "                mi = freq_re_muito_irrelevante[palavra]# + alpha \n",
    "\n",
    "            if (mr > r) and (mr > n) and (mr > i) and (mr > mi):\n",
    "                #print('mr')\n",
    "                dict_relevancia_palavras[palavra] = 4\n",
    "                #break\n",
    "            elif (r > mr) and (r > n) and (r > i) and (r > mi):\n",
    "                #print('r')\n",
    "                dict_relevancia_palavras[palavra] = 3\n",
    "                #break\n",
    "            elif (n > mr) and (n > r) and (n > i) and (n > mi):\n",
    "                #print('n')\n",
    "                dict_relevancia_palavras[palavra] = 2\n",
    "                #break\n",
    "            elif (i > mr) and (i > r) and (i > n) and (i > mi):\n",
    "                #print('i')\n",
    "                dict_relevancia_palavras[palavra] = 1\n",
    "                #break\n",
    "            elif (mi > mr) and (mi > r) and (mi > n) and (mi > i):\n",
    "                #print('mi')\n",
    "                dict_relevancia_palavras[palavra] = 0\n",
    "                #break\n",
    "    #return dict_relevancia_palavras[palavra]\n",
    "dict_relevancia_palavras\n",
    "#classificador_relevancia('casa')\n",
    "break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "### Verificando a performance do Classificador\n",
    "\n",
    "Agora você deve testar o seu classificador com a base de Testes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "test['Teste'] = test['Teste'].apply(cleanup)\n",
    "test['Teste'] = test['Teste'].str.lower()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "### Concluindo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "## Aperfeiçoamento:\n",
    "\n",
    "Os trabalhos vão evoluir em conceito dependendo da quantidade de itens avançados:\n",
    "\n",
    "* Limpar: \\n, :, \", ', (, ), etc SEM remover emojis\n",
    "* Corrigir separação de espaços entre palavras e emojis ou entre emojis e emojis\n",
    "* Propor outras limpezas e transformações que não afetem a qualidade da informação ou classificação\n",
    "* Criar categorias intermediárias de relevância baseadas na probabilidade: ex.: muito relevante, relevante, neutro, irrelevante, muito irrelevante (3 categorias: C, mais categorias conta para B)\n",
    "* Explicar por que não posso usar o próprio classificador para gerar mais amostras de treinamento\n",
    "* Propor diferentes cenários para Naïve Bayes fora do contexto do projeto\n",
    "* Sugerir e explicar melhorias reais com indicações concretas de como implementar (indicar como fazer e indicar material de pesquisa)\n",
    "* Montar um dashboard que realiza análise de sentimento e visualiza estes dados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "## Referências"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Naive Bayes and Text Classification](https://arxiv.org/pdf/1410.5329.pdf)  **Mais completo**\n",
    "\n",
    "[A practical explanation of a Naive Bayes Classifier](https://monkeylearn.com/blog/practical-explanation-naive-bayes-classifier/) **Mais simples**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
