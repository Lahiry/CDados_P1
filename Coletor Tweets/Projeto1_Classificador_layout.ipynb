{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Projeto 1 - Ciência dos Dados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nome: Raphael Lahiry de Barros\n",
    "\n",
    "Nome: Florencia Averame Kramer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# O que temos que fazer?\n",
    "precisamos criar um dataframe para cada relevância   OK\n",
    "\n",
    "dentro desses dataframes separar as frases em palavras OK   \n",
    "\n",
    "analisar a freq relativa de cada palavra --> probabilidade daquela palavra pertencer àquela relevância    \n",
    "\n",
    "quando quisermos avaliar o teste--> analisamos a probabilidade de cada palavra de uma frase pertencer a uma relevância (usar o smoothing -- aula 8 -- para as palavras que talvez não existam em certas categorias)  \n",
    "\n",
    "com isso, para cada palavra teremos a probabilidade de que esta pertença a cada relevância  \n",
    "a relevância com maior probabilidade será a daquela palavra"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Atenção:** Serão permitidos grupos de três pessoas, mas com uma rubrica mais exigente. Grupos deste tamanho precisarão fazer um questionário de avaliação de trabalho em equipe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "## Carregando algumas bibliotecas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Em `filename`, coloque o nome do seu arquivo de dados!**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encontrei o arquivo ps4.xlsx, tudo certo para prosseguir com a prova!\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "filename = 'ps4.xlsx'\n",
    "if filename in os.listdir():\n",
    "    print(f'Encontrei o arquivo {filename}, tudo certo para prosseguir com a prova!')\n",
    "else:\n",
    "    print(f'Não encontrei o arquivo {filename} aqui no diretório {os.getcwd()}, será que você não baixou o arquivo?')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Carregando a base de dados com os tweets classificados como relevantes e não relevantes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Treinamento</th>\n",
       "      <th>Relevância</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>@odonodocabare_ comprei um tablet dia desses e...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>@encanadorchapad o negócio é o ps4 slim. peque...</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>rt @ps3brasil: tohu é anunciado para ps4; deta...</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>dividindo essa semana entre dois jogos no modo...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>@leobruto @fridaygus @douglasxavier8 @ocerveje...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         Treinamento  Relevância\n",
       "0  @odonodocabare_ comprei um tablet dia desses e...         0.0\n",
       "1  @encanadorchapad o negócio é o ps4 slim. peque...         4.0\n",
       "2  rt @ps3brasil: tohu é anunciado para ps4; deta...         2.0\n",
       "3  dividindo essa semana entre dois jogos no modo...         0.0\n",
       "4  @leobruto @fridaygus @douglasxavier8 @ocerveje...         0.0"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train = pd.read_excel(filename)\n",
    "train.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['Treinamento'] = train['Treinamento'].astype('str')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Teste</th>\n",
       "      <th>Relevância</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>@chaehobbit simmm sou apaixonada em jogos assi...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>@pimps_junin @joao_almirante atleta nato , pod...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>@isa_boechatt kkkk vc joga onde no xbox ps4 ou...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>@vezguu eu sou ps4</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>path of exile (ps4) - farmando e fazendo o atl...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Teste  Relevância\n",
       "0  @chaehobbit simmm sou apaixonada em jogos assi...         1.0\n",
       "1  @pimps_junin @joao_almirante atleta nato , pod...         1.0\n",
       "2  @isa_boechatt kkkk vc joga onde no xbox ps4 ou...         1.0\n",
       "3                                 @vezguu eu sou ps4         1.0\n",
       "4  path of exile (ps4) - farmando e fazendo o atl...         0.0"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = pd.read_excel(filename, sheet_name = 'Teste')\n",
    "test.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "test['Teste'] = test['Teste'].astype('str')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "## Classificador automático de sentimento\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Faça aqui uma descrição do seu produto e o que considerou como relevante ou não relevante na classificação dos tweets.\n",
    "\n",
    "Nosso produto é o playstation 4. Consideramos relevantes as mensagens que falavam sobre questões técnicas do produto e sobre satisfação, sejam positivas ou negativas. Consideramos irrelevantes as mensagens que só mencionavam o nosso produtos nas '#' ou que eram opiniões pessoais que não agregavam na nossa análise."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "## Montando um Classificador Naive-Bayes\n",
    "\n",
    "Considerando apenas as mensagens da planilha Treinamento, ensine  seu classificador."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#função que apaga os caracteres especiais e as menções de usuários\n",
    "# https://docs.python.org/3/library/re.html#\n",
    "import re \n",
    "\n",
    "\n",
    "def cleanup(text):\n",
    "    \"\"\"\n",
    "        Função de limpeza muito simples que troca alguns sinais básicos por espaços\n",
    "    \"\"\"\n",
    "    #import string\n",
    "    punctuation = '[!-.:?;[]]' # Note que os sinais [] são delimitadores de um conjunto.\n",
    "    pattern = re.compile(punctuation)\n",
    "    text_subbed = re.sub(pattern, '', text)\n",
    "    \n",
    "    #filtro que remove as menções à usuários com @\n",
    "    filtro = filter(lambda x:x[0]!='@', text_subbed.split())\n",
    "    juncao = \" \".join(filter(lambda x:x[0]!='@', text_subbed.split()))\n",
    "    \n",
    "    return juncao\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#aplicando a função cleanup na base treinamento e deixando tudo em letra minúscula\n",
    "train['Treinamento'] = train['Treinamento'].apply(cleanup)\n",
    "train['Treinamento'] = train['Treinamento'].str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['Relevância'] = train['Relevância'].astype('category')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      Muito irrelevante\n",
       "1        Muito relevante\n",
       "2                 Neutro\n",
       "3      Muito irrelevante\n",
       "4      Muito irrelevante\n",
       "             ...        \n",
       "746          Irrelevante\n",
       "747          Irrelevante\n",
       "748               Neutro\n",
       "749    Muito irrelevante\n",
       "750          Irrelevante\n",
       "Name: Relevância, Length: 751, dtype: category\n",
       "Categories (5, object): [Muito irrelevante < Irrelevante < Neutro < Relevante < Muito relevante]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train['Relevância'].cat.categories = ['Muito irrelevante', 'Irrelevante', 'Neutro', 'Relevante', 'Muito relevante']\n",
    "train['Relevância'].cat.as_ordered()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ligando a relevância à um número\n",
    "muito_relevante = train['Relevância'] == 'Muito relevante'\n",
    "relevante = train['Relevância'] == 'Relevante'\n",
    "neutro = train['Relevância'] == 'Neutro'\n",
    "irrelevante = train['Relevância'] == 'Irrelevante'\n",
    "muito_irrelevante = train['Relevância'] == 'Muito irrelevante'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Treinamento</th>\n",
       "      <th>Relevância</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>comprei um tablet dia desses e to bem feliz......</td>\n",
       "      <td>Muito irrelevante</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>o negócio é o ps4 slim. pequeno e silencioso, ...</td>\n",
       "      <td>Muito relevante</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>rt tohu é anunciado para ps4; detalhes e gamep...</td>\n",
       "      <td>Neutro</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>dividindo essa semana entre dois jogos no modo...</td>\n",
       "      <td>Muito irrelevante</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>sentiu ? kkkkk. só fiz uma pergunta bem simple...</td>\n",
       "      <td>Muito irrelevante</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         Treinamento         Relevância\n",
       "0  comprei um tablet dia desses e to bem feliz......  Muito irrelevante\n",
       "1  o negócio é o ps4 slim. pequeno e silencioso, ...    Muito relevante\n",
       "2  rt tohu é anunciado para ps4; detalhes e gamep...             Neutro\n",
       "3  dividindo essa semana entre dois jogos no modo...  Muito irrelevante\n",
       "4  sentiu ? kkkkk. só fiz uma pergunta bem simple...  Muito irrelevante"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Filtros para criar os dataFrames com cada relevância"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_muito_relevante = train.loc[muito_relevante, :]\n",
    "df_relevante = train.loc[relevante, :]\n",
    "df_neutro = train.loc[neutro, :]\n",
    "df_irrelevante = train.loc[irrelevante, :]\n",
    "df_muito_irrelevante = train.loc[muito_irrelevante, :]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Separando cada coluna de relevância em listas de palavras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "palavras_muito_relevantes = []\n",
    "lista_vrw = []\n",
    "for vrw in df_muito_relevante['Treinamento']:\n",
    "    palavras_muito_relevantes.append(vrw.split(' '))\n",
    "for vrl in palavras_muito_relevantes:\n",
    "    lista_vrw += vrl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "palavras_relevantes = []\n",
    "lista_rw = []\n",
    "for rw in df_relevante['Treinamento']:\n",
    "    palavras_relevantes.append(rw.split(' '))\n",
    "for rl in palavras_relevantes:\n",
    "    lista_rw += rl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "palavras_neutras = []\n",
    "lista_nw = []\n",
    "for nw in df_neutro['Treinamento']:\n",
    "    palavras_neutras.append(nw.split(' '))\n",
    "for nl in palavras_neutras:\n",
    "    lista_nw += nl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "palavras_irrelevantes = []\n",
    "lista_iw = []\n",
    "for iw in df_irrelevante['Treinamento']:\n",
    "    palavras_irrelevantes.append(iw.split(' '))\n",
    "for il in palavras_irrelevantes:\n",
    "    lista_iw += il"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "palavras_muito_irrelevantes = []\n",
    "lista_viw = []\n",
    "for viw in df_muito_irrelevante['Treinamento']:\n",
    "    palavras_muito_irrelevantes.append(viw.split(' '))\n",
    "for vil in palavras_muito_irrelevantes:\n",
    "    lista_viw += vil"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transformando as listas de palavras de cada relevância em pd.Series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "serie_muito_relevante = pd.Series(lista_vrw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "serie_relevante = pd.Series(lista_rw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "serie_neutro = pd.Series(lista_nw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "serie_irrelevante = pd.Series(lista_iw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "serie_muito_irrelevante = pd.Series(lista_viw)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Frequências relativas e absolutas das palavras de cada relevância"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0008237232289950577\n"
     ]
    }
   ],
   "source": [
    "freq_ab_muito_relevante = serie_muito_relevante.value_counts() \n",
    "freq_re_muito_relevante = serie_muito_relevante.value_counts(True) \n",
    "\n",
    "print(freq_re_muito_relevante['igual'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'igual'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\indexes\\base.py\u001b[0m in \u001b[0;36mget_value\u001b[1;34m(self, series, key)\u001b[0m\n\u001b[0;32m   4410\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 4411\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mlibindex\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_value_at\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ms\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   4412\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mIndexError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.get_value_at\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.get_value_at\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\util.pxd\u001b[0m in \u001b[0;36mpandas._libs.util.get_value_at\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\util.pxd\u001b[0m in \u001b[0;36mpandas._libs.util.validate_indexer\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: 'str' object cannot be interpreted as an integer",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-133-246e7d8cf586>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mfreq_re_relevante\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mserie_relevante\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalue_counts\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfreq_re_relevante\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'igual'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\series.py\u001b[0m in \u001b[0;36m__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m    869\u001b[0m         \u001b[0mkey\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcom\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply_if_callable\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    870\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 871\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_value\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    872\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    873\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mis_scalar\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\indexes\\base.py\u001b[0m in \u001b[0;36mget_value\u001b[1;34m(self, series, key)\u001b[0m\n\u001b[0;32m   4417\u001b[0m                     \u001b[1;32mraise\u001b[0m \u001b[0mInvalidIndexError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4418\u001b[0m                 \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 4419\u001b[1;33m                     \u001b[1;32mraise\u001b[0m \u001b[0me1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   4420\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4421\u001b[0m                 \u001b[1;32mraise\u001b[0m \u001b[0me1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\indexes\\base.py\u001b[0m in \u001b[0;36mget_value\u001b[1;34m(self, series, key)\u001b[0m\n\u001b[0;32m   4403\u001b[0m         \u001b[0mk\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_convert_scalar_indexer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkind\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"getitem\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4404\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 4405\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_value\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ms\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mk\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtz\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mgetattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mseries\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"tz\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   4406\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4407\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m0\u001b[0m \u001b[1;32mand\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mholds_integer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mis_boolean\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_value\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_value\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'igual'"
     ]
    }
   ],
   "source": [
    "freq_ab_relevante = serie_relevante.value_counts()\n",
    "freq_re_relevante = serie_relevante.value_counts(True)\n",
    "\n",
    "print(freq_re_relevante['igual'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.00028546959748786756\n"
     ]
    }
   ],
   "source": [
    "freq_ab_neutro = serie_neutro.value_counts()\n",
    "freq_re_neutro = serie_neutro.value_counts(True)\n",
    "\n",
    "print(freq_re_neutro['igual'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0005003752814610958\n"
     ]
    }
   ],
   "source": [
    "freq_ab_irrelevante = serie_irrelevante.value_counts()\n",
    "freq_re_irrelevante = serie_irrelevante.value_counts(True)\n",
    "\n",
    "print(freq_re_irrelevante['igual'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0006253908692933083\n"
     ]
    }
   ],
   "source": [
    "freq_ab_muito_irrelevante = serie_muito_irrelevante.value_counts()\n",
    "freq_re_muito_irrelevante = serie_muito_irrelevante.value_counts(True)\n",
    "\n",
    "print(freq_re_muito_irrelevante['igual'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Definindo a quantidade total de palavras na língua portuguesa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "#portugues são as palavras existes que a gente vai verificar a freq relativa e vamos somar um alpha pra garantir\n",
    "#que as palavras que não existem não zerem o classificador\n",
    "total_train = lista_vrw + lista_rw + lista_nw + lista_iw + lista_viw\n",
    "\n",
    "#na fórmula precisamos dividir pela quantidade de palavras na lingua portuguesa\n",
    "alpha = 1\n",
    "v = 1e6\n",
    "lingua_portuguesa = len(total_train) + alpha*v"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pd.series do português"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ps4                                 545\n",
       "o                                   463\n",
       "de                                  369\n",
       "e                                   359\n",
       "no                                  274\n",
       "                                   ... \n",
       "vaga                                  1\n",
       "otimos                                1\n",
       "legenda                               1\n",
       "&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;      1\n",
       "lanche                                1\n",
       "Length: 4270, dtype: int64"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "serie_total_train = pd.Series(total_train)\n",
    "serie_total_train.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Criando a probabilidade de cada relevância à priori"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n"
     ]
    }
   ],
   "source": [
    "p_mr = len(serie_muito_relevante)/len(serie_total_train)\n",
    "p_r = len(serie_relevante)/len(serie_total_train)\n",
    "p_n = len(serie_neutro)/len(serie_total_train)\n",
    "p_i = len(serie_irrelevante)/len(serie_total_train)\n",
    "p_mi = len(serie_muito_irrelevante)/len(serie_total_train)\n",
    "\n",
    "print(p_mr + p_r + p_n + p_i + p_mi)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Montando Naive-Bayes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classificador da relevância de cada palavra"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# lista muito relevante\n",
    "dict_relevancia_palavras = {}\n",
    "\n",
    "\n",
    "for palavra in total_train:\n",
    "    if (palavra not in lista_vrw) and (palavra not in lista_rw) and (palavra not in lista_nw) and (palavra not in lista_iw) and (palavra not in lista_viw):\n",
    "        mr = alpha/len(total_train)\n",
    "        r = alpha/len(total_train)\n",
    "        n = alpha/len(total_train)\n",
    "        i = alpha/len(total_train)\n",
    "        mi = alpha/len(total_train)\n",
    "        \n",
    "    if palavra in lista_vrw:\n",
    "        mr = freq_re_muito_relevante[palavra] \n",
    "       \n",
    "    if palavra in lista_rw:\n",
    "        r = freq_re_relevante[palavra] \n",
    "       \n",
    "    if palavra in lista_nw:\n",
    "        n = freq_re_neutro[palavra] \n",
    "        \n",
    "    if palavra in lista_iw:\n",
    "        i = freq_re_irrelevante[palavra] \n",
    "       \n",
    "    if palavra in lista_viw:\n",
    "        mi = freq_re_muito_irrelevante[palavra] \n",
    "     \n",
    "    if (mr > r) and (mr > n) and (mr > i) and (mr > mi):\n",
    "        #print('mr')\n",
    "        dict_relevancia_palavras[palavra] = 4\n",
    "        #break\n",
    "    elif (r > mr) and (r > n) and (r > i) and (r > mi):\n",
    "        #print('r')\n",
    "        dict_relevancia_palavras[palavra] = 3\n",
    "        #break\n",
    "    elif (n > mr) and (n > r) and (n > i) and (n > mi):\n",
    "        #print('n')\n",
    "        dict_relevancia_palavras[palavra] = 2\n",
    "        #break\n",
    "    elif (i > mr) and (i > r) and (i > n) and (i > mi):\n",
    "        #print('i')\n",
    "        dict_relevancia_palavras[palavra] = 1\n",
    "        #break\n",
    "    elif (mi > mr) and (mi > r) and (mi > n) and (mi > i):\n",
    "        #print('mi')\n",
    "        dict_relevancia_palavras[palavra] = 0\n",
    "        #break\n",
    "    \n",
    "dict_relevancia_palavras['igual']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ENTROU NO ELSE\n",
      "mr\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# lista muito relevante\n",
    "\n",
    "def classificador_relevancia(palavra):\n",
    "    \n",
    "    dict_relevancia_palavras = {}\n",
    "    \n",
    "    if palavra not in total_train:\n",
    "        dict_relevancia_palavras[palavra] = alpha/lingua_portuguesa\n",
    "        print('NÂO EXISTIA DENTRO DE TRAIN')\n",
    "        \n",
    "    else:\n",
    "        print(\"ENTROU NO ELSE\")\n",
    "        mr=0\n",
    "        r=0\n",
    "        n=0\n",
    "        i=0\n",
    "        mi=0\n",
    "            \n",
    "        if palavra in lista_vrw:\n",
    "            mr = freq_re_muito_relevante[palavra] + (alpha/lingua_portuguesa)\n",
    "\n",
    "        if palavra in lista_rw:\n",
    "            r = freq_re_relevante[palavra] + (alpha/lingua_portuguesa) \n",
    "\n",
    "        if palavra in lista_nw:\n",
    "            n = freq_re_neutro[palavra] + (alpha/lingua_portuguesa) \n",
    "\n",
    "        if palavra in lista_iw:\n",
    "            i = freq_re_irrelevante[palavra] + (alpha/lingua_portuguesa) \n",
    "\n",
    "        if palavra in lista_viw:\n",
    "            mi = freq_re_muito_irrelevante[palavra] + (alpha/lingua_portuguesa) \n",
    "\n",
    "        if (mr > r) and (mr > n) and (mr > i) and (mr > mi):\n",
    "            print('mr')\n",
    "            dict_relevancia_palavras[palavra] = 4\n",
    "\n",
    "        elif (r > mr) and (r > n) and (r > i) and (r > mi):\n",
    "            print('r')\n",
    "            dict_relevancia_palavras[palavra] = 3\n",
    "\n",
    "        elif (n > mr) and (n > r) and (n > i) and (n > mi):\n",
    "            print('n')\n",
    "            dict_relevancia_palavras[palavra] = 2\n",
    "\n",
    "        elif (i > mr) and (i > r) and (i > n) and (i > mi):\n",
    "            print('i')\n",
    "            dict_relevancia_palavras[palavra] = 1\n",
    "\n",
    "        elif (mi > mr) and (mi > r) and (mi > n) and (mi > i):\n",
    "            print('mi')\n",
    "            dict_relevancia_palavras[palavra] = 0\n",
    "\n",
    "    return dict_relevancia_palavras[palavra]\n",
    "\n",
    "classificador_relevancia('igual')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# criar a função que retorna a probabilidade da frase pertencer à uma cateogria específica de relevância com base nas palavras que à compõem"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "### Verificando a performance do Classificador\n",
    "\n",
    "Agora você deve testar o seu classificador com a base de Testes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "test['Teste'] = test['Teste'].apply(cleanup)\n",
    "test['Teste'] = test['Teste'].str.lower()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "### Concluindo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "## Aperfeiçoamento:\n",
    "\n",
    "Os trabalhos vão evoluir em conceito dependendo da quantidade de itens avançados:\n",
    "\n",
    "* Limpar: \\n, :, \", ', (, ), etc SEM remover emojis\n",
    "* Corrigir separação de espaços entre palavras e emojis ou entre emojis e emojis\n",
    "* Propor outras limpezas e transformações que não afetem a qualidade da informação ou classificação\n",
    "* Criar categorias intermediárias de relevância baseadas na probabilidade: ex.: muito relevante, relevante, neutro, irrelevante, muito irrelevante (3 categorias: C, mais categorias conta para B)\n",
    "* Explicar por que não posso usar o próprio classificador para gerar mais amostras de treinamento\n",
    "* Propor diferentes cenários para Naïve Bayes fora do contexto do projeto\n",
    "* Sugerir e explicar melhorias reais com indicações concretas de como implementar (indicar como fazer e indicar material de pesquisa)\n",
    "* Montar um dashboard que realiza análise de sentimento e visualiza estes dados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "## Referências"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Naive Bayes and Text Classification](https://arxiv.org/pdf/1410.5329.pdf)  **Mais completo**\n",
    "\n",
    "[A practical explanation of a Naive Bayes Classifier](https://monkeylearn.com/blog/practical-explanation-naive-bayes-classifier/) **Mais simples**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
