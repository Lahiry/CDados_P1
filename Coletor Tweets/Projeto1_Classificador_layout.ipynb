{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Projeto 1 - Ciência dos Dados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nome: Raphael Lahiry de Barros\n",
    "\n",
    "Nome: Florencia Averame Kramer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "## Carregando algumas bibliotecas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "from math import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Em `filename`, coloque o nome do seu arquivo de dados!**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encontrei o arquivo ps4.xlsx, tudo certo para prosseguir com a prova!\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "filename = 'ps4.xlsx'\n",
    "if filename in os.listdir():\n",
    "    print(f'Encontrei o arquivo {filename}, tudo certo para prosseguir com a prova!')\n",
    "else:\n",
    "    print(f'Não encontrei o arquivo {filename} aqui no diretório {os.getcwd()}, será que você não baixou o arquivo?')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Carregando a base de dados com os tweets classificados como relevantes e não relevantes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Treinamento</th>\n",
       "      <th>Relevância</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>@odonodocabare_ comprei um tablet dia desses e...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>@encanadorchapad o negócio é o ps4 slim. peque...</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>rt @ps3brasil: tohu é anunciado para ps4; deta...</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>dividindo essa semana entre dois jogos no modo...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>@leobruto @fridaygus @douglasxavier8 @ocerveje...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         Treinamento  Relevância\n",
       "0  @odonodocabare_ comprei um tablet dia desses e...         0.0\n",
       "1  @encanadorchapad o negócio é o ps4 slim. peque...         4.0\n",
       "2  rt @ps3brasil: tohu é anunciado para ps4; deta...         2.0\n",
       "3  dividindo essa semana entre dois jogos no modo...         0.0\n",
       "4  @leobruto @fridaygus @douglasxavier8 @ocerveje...         0.0"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train = pd.read_excel(filename)\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['Treinamento'] = train['Treinamento'].astype('str')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "## Classificador automático de sentimento\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Faça aqui uma descrição do seu produto e o que considerou como relevante ou não relevante na classificação dos tweets.\n",
    "\n",
    "Nosso produto é o playstation 4. Consideramos relevantes as mensagens que falavam sobre questões técnicas do produto e sobre satisfação, sejam positivas ou negativas. Consideramos irrelevantes as mensagens que só mencionavam o nosso produtos nas '#' ou que eram opiniões pessoais que não agregavam na nossa análise."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "## Montando um Classificador Naive-Bayes\n",
    "\n",
    "Considerando apenas as mensagens da planilha Treinamento, ensine  seu classificador."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "#função que apaga os caracteres especiais e as menções de usuários\n",
    "# https://docs.python.org/3/library/re.html#\n",
    "import re \n",
    "\n",
    "\n",
    "def cleanup(text):\n",
    "    \"\"\"\n",
    "        Função de limpeza muito simples que troca alguns sinais básicos por espaços\n",
    "    \"\"\"\n",
    "    #import string\n",
    "    punctuation = '[!-.:?;\"\\n\"()''\"\",_%$\\|/,<>]'\n",
    "    pattern = re.compile(punctuation)\n",
    "    text_subbed = re.sub(pattern, '', text)\n",
    "    \n",
    "    #filtro que remove as menções à usuários com @\n",
    "    filtro = filter(lambda x:x[0]!='@', text_subbed.split())\n",
    "    juncao = \" \".join(filter(lambda x:x[0]!='@', text_subbed.split()))\n",
    "    \n",
    "    return juncao\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "#aplicando a função cleanup na base treinamento e deixando tudo em letra minúscula\n",
    "train['Treinamento'] = train['Treinamento'].apply(cleanup)\n",
    "train['Treinamento'] = train['Treinamento'].str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "#classificando a coluna Relevância como uma variável qualitativa ordinal\n",
    "train['Relevância'] = train['Relevância'].astype('category')\n",
    "train['Relevância'].cat.categories = ['Muito irrelevante', 'Irrelevante', 'Neutro', 'Relevante', 'Muito relevante']\n",
    "#train['Relevância'].cat.as_ordered()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Criando os filtros para criar os dataFrames por relevância"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "muito_relevante = train['Relevância'] == 'Muito relevante'\n",
    "relevante = train['Relevância'] == 'Relevante'\n",
    "neutro = train['Relevância'] == 'Neutro'\n",
    "irrelevante = train['Relevância'] == 'Irrelevante'\n",
    "muito_irrelevante = train['Relevância'] == 'Muito irrelevante'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Criando os dataFrames separados por relevância"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_muito_relevante = train.loc[muito_relevante, :]\n",
    "df_relevante = train.loc[relevante, :]\n",
    "df_neutro = train.loc[neutro, :]\n",
    "df_irrelevante = train.loc[irrelevante, :]\n",
    "df_muito_irrelevante = train.loc[muito_irrelevante, :]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Separando cada dataFrame da sua respectiva relevância em listas de palavras e em listas de tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "tweets_muito_relevantes = []\n",
    "lista_vrw = []\n",
    "for vrw in df_muito_relevante['Treinamento']:\n",
    "    tweets_muito_relevantes.append(vrw.split(' '))\n",
    "for vrl in tweets_muito_relevantes:\n",
    "    lista_vrw += vrl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets_relevantes = []\n",
    "lista_rw = []\n",
    "for rw in df_relevante['Treinamento']:\n",
    "    tweets_relevantes.append(rw.split(' '))\n",
    "for rl in tweets_relevantes:\n",
    "    lista_rw += rl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets_neutros = []\n",
    "lista_nw = []\n",
    "for nw in df_neutro['Treinamento']:\n",
    "    tweets_neutros.append(nw.split(' '))\n",
    "for nl in tweets_neutros:\n",
    "    lista_nw += nl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets_irrelevantes = []\n",
    "lista_iw = []\n",
    "for iw in df_irrelevante['Treinamento']:\n",
    "    tweets_irrelevantes.append(iw.split(' '))\n",
    "for il in tweets_irrelevantes:\n",
    "    lista_iw += il"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets_muito_irrelevantes = []\n",
    "lista_viw = []\n",
    "for viw in df_muito_irrelevante['Treinamento']:\n",
    "    tweets_muito_irrelevantes.append(viw.split(' '))\n",
    "for vil in tweets_muito_irrelevantes:\n",
    "    lista_viw += vil"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transformando as listas de palavras de cada relevância em pd.Series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "serie_muito_relevante = pd.Series(lista_vrw)\n",
    "serie_relevante = pd.Series(lista_rw)\n",
    "serie_neutro = pd.Series(lista_nw)\n",
    "serie_irrelevante = pd.Series(lista_iw)\n",
    "serie_muito_irrelevante = pd.Series(lista_viw)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Definindo os parâmetros para realizar o 'smoothing'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "#alpha é um \"chute\" da frequência absoluta das palavras que não estão em nenhum tweet classificado\n",
    "#utilizamos a variante Laplace Smoothing (alpha = 1)\n",
    "alpha = 1\n",
    "\n",
    "#v é um \"chute\" da quantidade de palavras existentes na língua potuguesa que não estão nos tweets classificados\n",
    "v = 1e4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Frequências relativas e absolutas das palavras de cada relevância"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "#muito relevante\n",
    "freq_ab_mr = serie_muito_relevante.value_counts() \n",
    "freq_re_mr = (freq_ab_mr + alpha)/(freq_ab_mr.sum() + (alpha*v))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "#relevante\n",
    "freq_ab_r = serie_relevante.value_counts() \n",
    "freq_re_r = (freq_ab_r + alpha)/(freq_ab_r.sum() + (alpha*v))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "#neutro\n",
    "freq_ab_n = serie_neutro.value_counts() \n",
    "freq_re_n = (freq_ab_n + alpha)/(freq_ab_n.sum() + (alpha*v))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "#irrelevante\n",
    "freq_ab_i = serie_irrelevante.value_counts() \n",
    "freq_re_i = (freq_ab_i + alpha)/(freq_ab_i.sum() + (alpha*v)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "#muito irrelevante\n",
    "freq_ab_mi = serie_muito_irrelevante.value_counts() \n",
    "freq_re_mi = (freq_ab_mi + alpha)/(freq_ab_mi.sum() + (alpha*v))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Montando Naive-Bayes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Probabilidade de cada relevância à priori"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9986684420772303\n"
     ]
    }
   ],
   "source": [
    "#contagem de tweets\n",
    "p_mr = len(tweets_muito_relevantes) / len(train[\"Treinamento\"])\n",
    "p_r = len(tweets_relevantes) / len(train[\"Treinamento\"])\n",
    "p_n = len(tweets_neutros) / len(train[\"Treinamento\"])\n",
    "p_i = len(tweets_irrelevantes) / len(train[\"Treinamento\"])\n",
    "p_mi = len(tweets_muito_irrelevantes) / len(train[\"Treinamento\"])\n",
    "\n",
    "print(p_mr + p_r + p_n + p_i + p_mi)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Função que retorna a probabilidade de uma frase pertencer à uma cateogria específica de relevância com base nas palavras que a compõem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "def datawitter(frase):\n",
    "    \n",
    "    prob_frase_dado_mr = 1\n",
    "    prob_frase_dado_r = 1\n",
    "    prob_frase_dado_n = 1\n",
    "    prob_frase_dado_i = 1\n",
    "    prob_frase_dado_mi = 1\n",
    "    \n",
    "    frase = frase.split(' ')\n",
    "    \n",
    "    for palavra in frase:\n",
    "        if palavra in freq_re_mr:\n",
    "            prob_frase_dado_mr *= freq_re_mr[palavra]\n",
    "        elif palavra not in freq_re_mr:\n",
    "            prob_frase_dado_mr *= (alpha/(freq_ab_mr.sum() + (alpha*v))) \n",
    "            \n",
    "        if palavra in freq_re_r:\n",
    "            prob_frase_dado_r *= freq_re_r[palavra]\n",
    "        elif palavra not in freq_re_r:\n",
    "            prob_frase_dado_r *= (alpha/(freq_ab_r.sum() + (alpha*v)))      \n",
    "            \n",
    "        if palavra in freq_re_n:\n",
    "            prob_frase_dado_n *= freq_re_n[palavra]\n",
    "        elif palavra not in freq_re_n:\n",
    "            prob_frase_dado_n *= (alpha/(freq_ab_n.sum() + (alpha*v)))\n",
    "            \n",
    "        if palavra in freq_re_i:\n",
    "            prob_frase_dado_i *= freq_re_i[palavra]\n",
    "        elif palavra not in freq_re_i:\n",
    "            prob_frase_dado_i *= (alpha/(freq_ab_i.sum() + (alpha*v)))\n",
    "            \n",
    "        if palavra in freq_re_mi:\n",
    "            prob_frase_dado_mi *= freq_re_mi[palavra]\n",
    "        elif palavra not in freq_re_mi:\n",
    "            prob_frase_dado_mi *= (alpha/(freq_ab_mi.sum() + (alpha*v)))\n",
    "            \n",
    "       \n",
    "    prob_mr_dado_frase = prob_frase_dado_mr*p_mr\n",
    " \n",
    "    prob_r_dado_frase = prob_frase_dado_r*p_r\n",
    "\n",
    "    prob_n_dado_frase = prob_frase_dado_n*p_n\n",
    "\n",
    "    prob_i_dado_frase = prob_frase_dado_i*p_i\n",
    "\n",
    "    prob_mi_dado_frase = prob_frase_dado_mi*p_mi\n",
    "    \n",
    "    \n",
    "    if max(log(prob_mr_dado_frase, 10), log(prob_r_dado_frase, 10), log(prob_n_dado_frase, 10), log(prob_i_dado_frase, 10),  log(prob_mi_dado_frase, 10)) == log(prob_mr_dado_frase, 10):\n",
    "        return 'Muito relevante'\n",
    "    if max(log(prob_mr_dado_frase, 10), log(prob_r_dado_frase, 10), log(prob_n_dado_frase, 10), log(prob_i_dado_frase, 10),  log(prob_mi_dado_frase, 10)) == log(prob_r_dado_frase, 10): \n",
    "        return 'Relevante'\n",
    "    if max(log(prob_mr_dado_frase, 10), log(prob_r_dado_frase, 10), log(prob_n_dado_frase, 10), log(prob_i_dado_frase, 10),  log(prob_mi_dado_frase, 10)) == log(prob_n_dado_frase, 10): \n",
    "        return 'Neutro'\n",
    "    if max(log(prob_mr_dado_frase, 10), log(prob_r_dado_frase, 10), log(prob_n_dado_frase, 10), log(prob_i_dado_frase, 10),  log(prob_mi_dado_frase, 10)) == log(prob_i_dado_frase, 10):\n",
    "        return 'Irrelevante'\n",
    "    if max(log(prob_mr_dado_frase, 10), log(prob_r_dado_frase, 10), log(prob_n_dado_frase, 10), log(prob_i_dado_frase, 10),  log(prob_mi_dado_frase, 10)) == log(prob_mi_dado_frase, 10): \n",
    "        return 'Muito irrelevante'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preenchimento da coluna contém a nossa classificação"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['Classificacao'] = train['Treinamento'].apply(datawitter)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tabela que compara as classificações que nós fizemos previamente à mão com as classificações dadas pelo nosso classificador"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Classificacao</th>\n",
       "      <th>Irrelevante</th>\n",
       "      <th>Muito irrelevante</th>\n",
       "      <th>Muito relevante</th>\n",
       "      <th>Neutro</th>\n",
       "      <th>Relevante</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Relevância</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Muito irrelevante</th>\n",
       "      <td>0.053333</td>\n",
       "      <td>0.214667</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.009333</td>\n",
       "      <td>0.001333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Irrelevante</th>\n",
       "      <td>0.290667</td>\n",
       "      <td>0.004000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.006667</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Neutro</th>\n",
       "      <td>0.017333</td>\n",
       "      <td>0.001333</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.192000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Relevante</th>\n",
       "      <td>0.017333</td>\n",
       "      <td>0.001333</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.004000</td>\n",
       "      <td>0.137333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Muito relevante</th>\n",
       "      <td>0.029333</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.005333</td>\n",
       "      <td>0.009333</td>\n",
       "      <td>0.005333</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Classificacao      Irrelevante  Muito irrelevante  Muito relevante    Neutro  \\\n",
       "Relevância                                                                     \n",
       "Muito irrelevante     0.053333           0.214667         0.000000  0.009333   \n",
       "Irrelevante           0.290667           0.004000         0.000000  0.006667   \n",
       "Neutro                0.017333           0.001333         0.000000  0.192000   \n",
       "Relevante             0.017333           0.001333         0.000000  0.004000   \n",
       "Muito relevante       0.029333           0.000000         0.005333  0.009333   \n",
       "\n",
       "Classificacao      Relevante  \n",
       "Relevância                    \n",
       "Muito irrelevante   0.001333  \n",
       "Irrelevante         0.000000  \n",
       "Neutro              0.000000  \n",
       "Relevante           0.137333  \n",
       "Muito relevante     0.005333  "
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tabela = pd.crosstab(train['Relevância'], train['Classificacao'], normalize='all')\n",
    "tabela"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Eficácia do nosso classificador"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'84%'"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#quanto o classificador acertou?\n",
    "f'{(tabela.iloc[0,1] + tabela.iloc[1,0] + tabela.iloc[2,3] + tabela.iloc[3,4] + tabela.iloc[4,2])*100:.5g}%'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "### Verificando a performance do Classificador\n",
    "\n",
    "Agora você deve testar o seu classificador com a base de Testes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transformando o dataFrame teste em string para poder aplicar a função cleanup e deixar o texto todo em minúscula"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = pd.read_excel(filename, sheet_name = 'Teste')\n",
    "test['Teste'] = test['Teste'].astype('str')\n",
    "test['Teste'] = test['Teste'].apply(cleanup)\n",
    "test['Teste'] = test['Teste'].str.lower()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transformando a coluna 'Relevância' em categórica"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "test['Relevância'] = test['Relevância'].astype('category')\n",
    "test['Relevância'].cat.categories = ['Muito irrelevante', 'Irrelevante', 'Neutro', 'Relevante', 'Muito relevante']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preenchendo a coluna que contêm as classificações do nosso classificador"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test['Classificador'] = test['Teste'].apply(datawitter)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tabela que compara as classificações que nós fizemos previamente à mão com as classificações dadas pelo nosso classificador"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tabela2 = pd.crosstab(test['Relevância'], test['Classificador'], normalize='all')\n",
    "tabela2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Eficácia do nosso classificador"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#quanto o classificador acertou?\n",
    "#o último 0 representa que não há tweets classificados como muito relevantes no nosso teste\n",
    "f'O acerto do nosso classificador foi de: {(tabela2.iloc[0,1]+tabela2.iloc[1,0]+tabela2.iloc[2,2]+tabela2.iloc[3,3]+0)*100:.5g}%'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "# Concluindo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Porcentagem de verdadeiros muito relevantes e falsos muito relevantes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Porcentagem de mensagens muito relevantes que foram classificadas como muito relevantes: {(0)}%')\n",
    "print()\n",
    "print(f'Porcentagem de mensagens muito relevantes que não foram classificadas como muito relevantes: {(1)*100:.5g}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Porcentagem de verdadeiros relevantes e falsos relevantes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(f'Porcentagem de mensagens relevantes que foram classificadas como relevantes: {(tabela2.iloc[3,3])*100:.5g}%')\n",
    "print()\n",
    "print(f'Porcentagem de mensagens relevantes que não foram classificadas como relevantes: {(1-tabela2.iloc[3,3])*100:.5g}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Porcentagem de verdadeiros neutros e falsos neutros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Porcentagem de mensagens neutras que foram classificadas como neutras: {(tabela2.iloc[2,2])*100:.5g}%')\n",
    "print()\n",
    "print(f'Porcentagem de mensagens neutras que não foram classificadas como neutras: {(1-tabela2.iloc[2,2])*100:.5g}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Porcentagem de verdadeiros irrelevantes e falsos irrelevantes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Porcentagem de mensagens irrelevantes que foram classificadas como irrelevantes: {(tabela2.iloc[1,0])*100:.5g}%')\n",
    "print()\n",
    "print(f'Porcentagem de mensagens irrelevantes que não foram classificadas como irrelevantes: {(1-tabela2.iloc[1,0])*100:.5g}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Porcentagem de verdadeiros muito irrelevantes e falsos muito irrelevantes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Porcentagem de mensagens muito irrelevantes que foram classificadas como muito irrelevantess: {(tabela2.iloc[0,1])*100:.5g}%')\n",
    "print()\n",
    "print(f'Porcentagem de mensagens muito irrelevantes que não foram classificadas como muito irrelevantes: {(1-tabela2.iloc[0,1])*100:.5g}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Como são tratadas as mensagens com dupla negação e sarcasmo?\n",
    "Como o classificador Naïve-Bayes trabalha exclusivamente com as probabilidades das palavras de uma frase pertencerem a uma certa categoria, ele não leva em consideração a ordem em que essas palavras acontecem, desta forma, não conseguindo analisar se uma frase possui sarcasmo ou dupla negação. Esse é um dos motivos pelos quais o classificador recebe o nome 'ingênuo (naive)'. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Por que não posso usar o próprio classificador para gerar mais amostras de treinamento?\n",
    "Não podemos utilizar o próprio classificador para gerar mais amostras de treinamento porque o classificador foi feito apartir das classificações de treinamento. Isso faz com que a eficácia do classificador se mostre como sendo muito alta, podendo não ser a realidade, já que os tweets que serão classificados são os que geraram os 'padrões' que criaram o classifcador."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Diferentes cenários para Naïve Bayes fora do contexto do projeto \n",
    "O classificador Naïve-Bayes também poderia ser utilizado em uma campanha política, onde se tem por objetivo saber o apoio que certo candidato está recebendo através das classificações das mensagens que o mencionam nas redes sociais (não só twitter).\n",
    "De um modo geral, o classificador Naïve-Bayes pode ser muito útil para se realizar uma análise automática de sentimento relacionada a qualquer produto/ marca/ pessoa. É um modo de se obter feedbacks de forma informal e sincera."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Melhorias possíveis para o classificador Naïve-Bayes\n",
    "Poderiamos obter uma classificação mais realista ao levar em consideração a ordem na qual as palavras aparecem nas frases e a probabilidade de certas sequências de palavras acontecerem. Com isso, poderiamos analisar a categoria de relevância / positividade / negativade da mensagem através da probailidade de que certa sequência se enquadre em algum desses cenários. \n",
    "\n",
    "1) https://www.organicadigital.com/blog/algoritmo-de-classificacao-naive-bayes/\n",
    "2) https://sebastianraschka.com/Articles/2014_naive_bayes_1.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dashboard que realiza análise de sentimento e visualiza estes dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dado = test['Classificador'].value_counts(True)\n",
    "\n",
    "colors = ['orange', 'yellow', 'green', 'red']\n",
    "\n",
    "dado.plot.bar(stacked = True, color=colors)\n",
    "    \n",
    "plt.xlabel('\\nRelevância dos tweets \"Teste\"\\n')\n",
    "plt.ylabel('\\nPorcentagem dos tweets \"Teste\"\\n')\n",
    "plt.title('\\nAnálise de sentimento do classificador\\n')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "## Referências"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Naive Bayes and Text Classification](https://arxiv.org/pdf/1410.5329.pdf)  **Mais completo**\n",
    "\n",
    "[A practical explanation of a Naive Bayes Classifier](https://monkeylearn.com/blog/practical-explanation-naive-bayes-classifier/) **Mais simples**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
