{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Projeto 1 - Ciência dos Dados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nome: Raphael Lahiry de Barros\n",
    "\n",
    "Nome: Florencia Averame Kramer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# O que temos que fazer?\n",
    "precisamos criar um dataframe para cada relevância   OK\n",
    "\n",
    "dentro desses dataframes separar as frases em palavras OK   \n",
    "\n",
    "analisar a freq relativa de cada palavra --> probabilidade daquela palavra pertencer àquela relevância    \n",
    "\n",
    "quando quisermos avaliar o teste--> analisamos a probabilidade de cada palavra de uma frase pertencer a uma relevância (usar o smoothing -- aula 8 -- para as palavras que talvez não existam em certas categorias)  \n",
    "\n",
    "com isso, para cada palavra teremos a probabilidade de que esta pertença a cada relevância  \n",
    "a relevância com maior probabilidade será a daquela palavra"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Atenção:** Serão permitidos grupos de três pessoas, mas com uma rubrica mais exigente. Grupos deste tamanho precisarão fazer um questionário de avaliação de trabalho em equipe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "## Carregando algumas bibliotecas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Em `filename`, coloque o nome do seu arquivo de dados!**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encontrei o arquivo ps4.xlsx, tudo certo para prosseguir com a prova!\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "filename = 'ps4.xlsx'\n",
    "if filename in os.listdir():\n",
    "    print(f'Encontrei o arquivo {filename}, tudo certo para prosseguir com a prova!')\n",
    "else:\n",
    "    print(f'Não encontrei o arquivo {filename} aqui no diretório {os.getcwd()}, será que você não baixou o arquivo?')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Carregando a base de dados com os tweets classificados como relevantes e não relevantes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Treinamento</th>\n",
       "      <th>Relevância</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>@odonodocabare_ comprei um tablet dia desses e...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>@encanadorchapad o negócio é o ps4 slim. peque...</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>rt @ps3brasil: tohu é anunciado para ps4; deta...</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>dividindo essa semana entre dois jogos no modo...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>@leobruto @fridaygus @douglasxavier8 @ocerveje...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         Treinamento  Relevância\n",
       "0  @odonodocabare_ comprei um tablet dia desses e...         0.0\n",
       "1  @encanadorchapad o negócio é o ps4 slim. peque...         4.0\n",
       "2  rt @ps3brasil: tohu é anunciado para ps4; deta...         2.0\n",
       "3  dividindo essa semana entre dois jogos no modo...         0.0\n",
       "4  @leobruto @fridaygus @douglasxavier8 @ocerveje...         0.0"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train = pd.read_excel(filename)\n",
    "train.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['Treinamento'] = train['Treinamento'].astype('str')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "## Classificador automático de sentimento\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Faça aqui uma descrição do seu produto e o que considerou como relevante ou não relevante na classificação dos tweets.\n",
    "\n",
    "Nosso produto é o playstation 4. Consideramos relevantes as mensagens que falavam sobre questões técnicas do produto e sobre satisfação, sejam positivas ou negativas. Consideramos irrelevantes as mensagens que só mencionavam o nosso produtos nas '#' ou que eram opiniões pessoais que não agregavam na nossa análise."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "## Montando um Classificador Naive-Bayes\n",
    "\n",
    "Considerando apenas as mensagens da planilha Treinamento, ensine  seu classificador."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "#função que apaga os caracteres especiais e as menções de usuários\n",
    "# https://docs.python.org/3/library/re.html#\n",
    "import re \n",
    "\n",
    "\n",
    "def cleanup(text):\n",
    "    \"\"\"\n",
    "        Função de limpeza muito simples que troca alguns sinais básicos por espaços\n",
    "    \"\"\"\n",
    "    #import string\n",
    "    punctuation = '[!-.:?;[]]' # Note que os sinais [] são delimitadores de um conjunto.\n",
    "    pattern = re.compile(punctuation)\n",
    "    text_subbed = re.sub(pattern, '', text)\n",
    "    \n",
    "    #filtro que remove as menções à usuários com @\n",
    "    filtro = filter(lambda x:x[0]!='@', text_subbed.split())\n",
    "    juncao = \" \".join(filter(lambda x:x[0]!='@', text_subbed.split()))\n",
    "    \n",
    "    return juncao\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "#aplicando a função cleanup na base treinamento e deixando tudo em letra minúscula\n",
    "train['Treinamento'] = train['Treinamento'].apply(cleanup)\n",
    "train['Treinamento'] = train['Treinamento'].str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['Relevância'] = train['Relevância'].astype('category')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      Muito irrelevante\n",
       "1        Muito relevante\n",
       "2                 Neutro\n",
       "3      Muito irrelevante\n",
       "4      Muito irrelevante\n",
       "             ...        \n",
       "746          Irrelevante\n",
       "747          Irrelevante\n",
       "748               Neutro\n",
       "749    Muito irrelevante\n",
       "750          Irrelevante\n",
       "Name: Relevância, Length: 751, dtype: category\n",
       "Categories (5, object): [Muito irrelevante < Irrelevante < Neutro < Relevante < Muito relevante]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train['Relevância'].cat.categories = ['Muito irrelevante', 'Irrelevante', 'Neutro', 'Relevante', 'Muito relevante']\n",
    "train['Relevância'].cat.as_ordered()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Criando os filtros para criar os dataFrames por relevância"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ligando a relevância à um número\n",
    "muito_relevante = train['Relevância'] == 'Muito relevante'\n",
    "relevante = train['Relevância'] == 'Relevante'\n",
    "neutro = train['Relevância'] == 'Neutro'\n",
    "irrelevante = train['Relevância'] == 'Irrelevante'\n",
    "muito_irrelevante = train['Relevância'] == 'Muito irrelevante'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Criando os dataFrames separados por relevância"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_muito_relevante = train.loc[muito_relevante, :]\n",
    "df_relevante = train.loc[relevante, :]\n",
    "df_neutro = train.loc[neutro, :]\n",
    "df_irrelevante = train.loc[irrelevante, :]\n",
    "df_muito_irrelevante = train.loc[muito_irrelevante, :]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Separando cada dataFrame da sua respectiva relevância em listas de palavras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "palavras_muito_relevantes = []\n",
    "lista_vrw = []\n",
    "for vrw in df_muito_relevante['Treinamento']:\n",
    "    palavras_muito_relevantes.append(vrw.split(' '))\n",
    "for vrl in palavras_muito_relevantes:\n",
    "    lista_vrw += vrl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "palavras_relevantes = []\n",
    "lista_rw = []\n",
    "for rw in df_relevante['Treinamento']:\n",
    "    palavras_relevantes.append(rw.split(' '))\n",
    "for rl in palavras_relevantes:\n",
    "    lista_rw += rl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "palavras_neutras = []\n",
    "lista_nw = []\n",
    "for nw in df_neutro['Treinamento']:\n",
    "    palavras_neutras.append(nw.split(' '))\n",
    "for nl in palavras_neutras:\n",
    "    lista_nw += nl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "palavras_irrelevantes = []\n",
    "lista_iw = []\n",
    "for iw in df_irrelevante['Treinamento']:\n",
    "    palavras_irrelevantes.append(iw.split(' '))\n",
    "for il in palavras_irrelevantes:\n",
    "    lista_iw += il"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "palavras_muito_irrelevantes = []\n",
    "lista_viw = []\n",
    "for viw in df_muito_irrelevante['Treinamento']:\n",
    "    palavras_muito_irrelevantes.append(viw.split(' '))\n",
    "for vil in palavras_muito_irrelevantes:\n",
    "    lista_viw += vil"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transformando as listas de palavras de cada relevância em pd.Series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "serie_muito_relevante = pd.Series(lista_vrw)\n",
    "serie_relevante = pd.Series(lista_rw)\n",
    "serie_neutro = pd.Series(lista_nw)\n",
    "serie_irrelevante = pd.Series(lista_iw)\n",
    "serie_muito_irrelevante = pd.Series(lista_viw)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Frequências relativas e absolutas das palavras de cada relevância"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "#muito relevante\n",
    "freq_ab_muito_relevante = serie_muito_relevante.value_counts() \n",
    "freq_re_muito_relevante = serie_muito_relevante.value_counts(True) + (alpha/lingua_portuguesa)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "#relevante\n",
    "freq_ab_relevante = serie_relevante.value_counts()\n",
    "freq_re_relevante = serie_relevante.value_counts(True) + (alpha/lingua_portuguesa)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "#neutro\n",
    "freq_ab_neutro = serie_neutro.value_counts()\n",
    "freq_re_neutro = serie_neutro.value_counts(True) + (alpha/lingua_portuguesa)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "#irrelevante\n",
    "freq_ab_irrelevante = serie_irrelevante.value_counts()\n",
    "freq_re_irrelevante = serie_irrelevante.value_counts(True) + (alpha/lingua_portuguesa)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "#muito irrelevante\n",
    "freq_ab_muito_irrelevante = serie_muito_irrelevante.value_counts()\n",
    "freq_re_muito_irrelevante = serie_muito_irrelevante.value_counts(True) + (alpha/lingua_portuguesa)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Definindo a quantidade total de palavras na língua portuguesa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "#total_train são as palavras existentes nos tweets de treinamento, nos quais verificaremos\n",
    "#a freq relativa e somaremos um alpha (que representa que a palavra apareceu uma vez) pra garantir\n",
    "#que as palavras que não existem nos tweets classificados não zerem o classificador\n",
    "total_train = lista_vrw + lista_rw + lista_nw + lista_iw + lista_viw\n",
    "\n",
    "#na fórmula precisamos dividir pela quantidade de palavras existentes na lingua portuguesa\n",
    "#para obter esse valor somamos a quantidade de palavras existentes nos tweets classificados \n",
    "#com um \"chute\" das palavras existentes que não estão em nenhum tweet classificado\n",
    "alpha = 1\n",
    "v = 1e6\n",
    "lingua_portuguesa = len(total_train) + alpha*v"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pd.series das palavras que aparecem nos tweets classificados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "serie_total_train = pd.Series(total_train)\n",
    "#serie_total_train.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Montando Naive-Bayes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classificador da relevância de cada palavra"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ENTROU NO ELSE\n",
      "r\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Relevante'"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# lista muito relevante\n",
    "\n",
    "def classificador_relev_palavra(palavra):\n",
    "    \n",
    "    dict_relevancia_palavras = {}\n",
    "    \n",
    "    if palavra not in total_train:\n",
    "        dict_relevancia_palavras[palavra] = (alpha/lingua_portuguesa)\n",
    "        print('NÂO EXISTIA DENTRO DE TRAIN')\n",
    "        \n",
    "    else:\n",
    "        print(\"ENTROU NO ELSE\")\n",
    "        mr=0\n",
    "        r=0\n",
    "        n=0\n",
    "        i=0\n",
    "        mi=0\n",
    "            \n",
    "        if palavra in lista_vrw:\n",
    "            mr = freq_re_muito_relevante[palavra] \n",
    "\n",
    "        if palavra in lista_rw:\n",
    "            r = freq_re_relevante[palavra] \n",
    "\n",
    "        if palavra in lista_nw:\n",
    "            n = freq_re_neutro[palavra]\n",
    "\n",
    "        if palavra in lista_iw:\n",
    "            i = freq_re_irrelevante[palavra] \n",
    "\n",
    "        if palavra in lista_viw:\n",
    "            mi = freq_re_muito_irrelevante[palavra] \n",
    "\n",
    "        if (mr > r) and (mr > n) and (mr > i) and (mr > mi):\n",
    "            print('mr')\n",
    "            dict_relevancia_palavras[palavra] = \"Muito relevante\"\n",
    "\n",
    "        elif (r > mr) and (r > n) and (r > i) and (r > mi):\n",
    "            print('r')\n",
    "            dict_relevancia_palavras[palavra] = \"Relevante\"\n",
    "\n",
    "        elif (n > mr) and (n > r) and (n > i) and (n > mi):\n",
    "            print('n')\n",
    "            dict_relevancia_palavras[palavra] = \"Neutro\"\n",
    "\n",
    "        elif (i > mr) and (i > r) and (i > n) and (i > mi):\n",
    "            print('i')\n",
    "            dict_relevancia_palavras[palavra] = \"Irrelevante\"\n",
    "\n",
    "        elif (mi > mr) and (mi > r) and (mi > n) and (mi > i):\n",
    "            print('mi')\n",
    "            dict_relevancia_palavras[palavra] = \"Muito irrelevante\"\n",
    "\n",
    "    return dict_relevancia_palavras[palavra]\n",
    "\n",
    "classificador_relev_palavra('amigos')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Criando a probabilidade de cada relevância à priori"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_mr = len(serie_muito_relevante)/len(serie_total_train)\n",
    "p_r = len(serie_relevante)/len(serie_total_train)\n",
    "p_n = len(serie_neutro)/len(serie_total_train)\n",
    "p_i = len(serie_irrelevante)/len(serie_total_train)\n",
    "p_mi = len(serie_muito_irrelevante)/len(serie_total_train)\n",
    "\n",
    "#print(p_mr + p_r + p_n + p_i + p_mi)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Criando a função que retorna a probabilidade de uma frase pertencer à uma cateogria específica de relevância com base nas palavras que à compõem\n",
    "\n",
    "#### 1º Prob (frase | relevância)\n",
    "#### 2º Prob (relevância | frase)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def datawitter(frase):\n",
    "    \n",
    "    palavras = frase.split(' ')\n",
    "    \n",
    "    mr = (alpha/lingua_portuguesa)\n",
    "    r = (alpha/lingua_portuguesa)\n",
    "    n = (alpha/lingua_portuguesa)\n",
    "    i = (alpha/lingua_portuguesa)\n",
    "    mi = (alpha/lingua_portuguesa)\n",
    "\n",
    "    \n",
    "    for palavra in palavras:\n",
    "     \n",
    "        if palavra not in total_train:\n",
    "            mr *= (alpha/lingua_portuguesa)\n",
    "            r *= (alpha/lingua_portuguesa)\n",
    "            n *= (alpha/lingua_portuguesa)\n",
    "            i *= (alpha/lingua_portuguesa)\n",
    "            mi *= (alpha/lingua_portuguesa)\n",
    "            print('NÂO EXISTIA DENTRO DE TRAIN')\n",
    "\n",
    "        else:\n",
    "            print(\"ENTROU NO ELSE\")\n",
    "\n",
    "            if palavra in lista_vrw:\n",
    "                mr *= freq_re_muito_relevante[palavra] \n",
    "\n",
    "            if palavra in lista_rw:\n",
    "                r *= freq_re_relevante[palavra] \n",
    "\n",
    "            if palavra in lista_nw:\n",
    "                n *= freq_re_neutro[palavra]\n",
    "\n",
    "            if palavra in lista_iw:\n",
    "                i *= freq_re_irrelevante[palavra] \n",
    "\n",
    "            if palavra in lista_viw:\n",
    "                mi *= freq_re_muito_irrelevante[palavra] \n",
    "\n",
    "                \n",
    "    if (mr > r) and (mr > n) and (mr > i) and (mr > mi):\n",
    "        print('mr')\n",
    "        dict_relevancia_palavras[palavra] = \"Muito relevante\"\n",
    "\n",
    "    elif (r > mr) and (r > n) and (r > i) and (r > mi):\n",
    "        print('r')\n",
    "        dict_relevancia_palavras[palavra] = \"Relevante\"\n",
    "\n",
    "    elif (n > mr) and (n > r) and (n > i) and (n > mi):\n",
    "        print('n')\n",
    "        dict_relevancia_palavras[palavra] = \"Neutro\"\n",
    "\n",
    "    elif (i > mr) and (i > r) and (i > n) and (i > mi):\n",
    "        print('i')\n",
    "        dict_relevancia_palavras[palavra] = \"Irrelevante\"\n",
    "\n",
    "    elif (mi > mr) and (mi > r) and (mi > n) and (mi > i):\n",
    "        print('mi')\n",
    "        dict_relevancia_palavras[palavra] = \"Muito irrelevante\"\n",
    "\n",
    "    return dict_relevancia_palavras[palavra]\n",
    "\n",
    "    classificador_relev_palavra('amigos')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "### Verificando a performance do Classificador\n",
    "\n",
    "Agora você deve testar o seu classificador com a base de Testes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = pd.read_excel(filename, sheet_name = 'Teste')\n",
    "test['Teste'] = test['Teste'].astype('str')\n",
    "test['Teste'] = test['Teste'].apply(cleanup)\n",
    "test['Teste'] = test['Teste'].str.lower()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "### Concluindo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "## Aperfeiçoamento:\n",
    "\n",
    "Os trabalhos vão evoluir em conceito dependendo da quantidade de itens avançados:\n",
    "\n",
    "* Limpar: \\n, :, \", ', (, ), etc SEM remover emojis\n",
    "* Corrigir separação de espaços entre palavras e emojis ou entre emojis e emojis\n",
    "* Propor outras limpezas e transformações que não afetem a qualidade da informação ou classificação\n",
    "* Criar categorias intermediárias de relevância baseadas na probabilidade: ex.: muito relevante, relevante, neutro, irrelevante, muito irrelevante (3 categorias: C, mais categorias conta para B)\n",
    "* Explicar por que não posso usar o próprio classificador para gerar mais amostras de treinamento\n",
    "* Propor diferentes cenários para Naïve Bayes fora do contexto do projeto\n",
    "* Sugerir e explicar melhorias reais com indicações concretas de como implementar (indicar como fazer e indicar material de pesquisa)\n",
    "* Montar um dashboard que realiza análise de sentimento e visualiza estes dados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "## Referências"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Naive Bayes and Text Classification](https://arxiv.org/pdf/1410.5329.pdf)  **Mais completo**\n",
    "\n",
    "[A practical explanation of a Naive Bayes Classifier](https://monkeylearn.com/blog/practical-explanation-naive-bayes-classifier/) **Mais simples**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
