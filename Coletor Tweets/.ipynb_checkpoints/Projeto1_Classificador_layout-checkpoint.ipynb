{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Projeto 1 - Ciência dos Dados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nome: Raphael Lahiry de Barros\n",
    "\n",
    "Nome: Florencia Averame Kramer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### O que temos que fazer?\n",
    "precisamos criar um dataframe para cada relevância   OK\n",
    "\n",
    "dentro desses dataframes separar as frases em palavras OK   \n",
    "\n",
    "analisar a freq relativa de cada palavra --> probabilidade daquela palavra pertencer àquela relevância    \n",
    "\n",
    "quando quisermos avaliar o teste--> analisamos a probabilidade de cada palavra de uma frase pertencer a uma relevância (usar o smoothing -- aula 8 -- para as palavras que talvez não existam em certas categorias)  \n",
    "\n",
    "com isso, para cada palavra teremos a probabilidade de que esta pertença a cada relevância  \n",
    "a relevância com maior probabilidade será a daquela palavra\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Dúvidas\n",
    "A tabela1 apresenta que os valores são iguais, mas a porcentagem da 2% (já obtivemos 95,7)\n",
    "A tabela2 apresenta 22,2%"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Atenção:** Serão permitidos grupos de três pessoas, mas com uma rubrica mais exigente. Grupos deste tamanho precisarão fazer um questionário de avaliação de trabalho em equipe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "## Carregando algumas bibliotecas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Em `filename`, coloque o nome do seu arquivo de dados!**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encontrei o arquivo ps4.xlsx, tudo certo para prosseguir com a prova!\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "filename = 'ps4.xlsx'\n",
    "if filename in os.listdir():\n",
    "    print(f'Encontrei o arquivo {filename}, tudo certo para prosseguir com a prova!')\n",
    "else:\n",
    "    print(f'Não encontrei o arquivo {filename} aqui no diretório {os.getcwd()}, será que você não baixou o arquivo?')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Carregando a base de dados com os tweets classificados como relevantes e não relevantes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Treinamento</th>\n",
       "      <th>Relevância</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>@odonodocabare_ comprei um tablet dia desses e...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>@encanadorchapad o negócio é o ps4 slim. peque...</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>rt @ps3brasil: tohu é anunciado para ps4; deta...</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>dividindo essa semana entre dois jogos no modo...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>@leobruto @fridaygus @douglasxavier8 @ocerveje...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         Treinamento  Relevância\n",
       "0  @odonodocabare_ comprei um tablet dia desses e...         0.0\n",
       "1  @encanadorchapad o negócio é o ps4 slim. peque...         4.0\n",
       "2  rt @ps3brasil: tohu é anunciado para ps4; deta...         2.0\n",
       "3  dividindo essa semana entre dois jogos no modo...         0.0\n",
       "4  @leobruto @fridaygus @douglasxavier8 @ocerveje...         0.0"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train = pd.read_excel(filename)\n",
    "train.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['Treinamento'] = train['Treinamento'].astype('str')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "## Classificador automático de sentimento\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Faça aqui uma descrição do seu produto e o que considerou como relevante ou não relevante na classificação dos tweets.\n",
    "\n",
    "Nosso produto é o playstation 4. Consideramos relevantes as mensagens que falavam sobre questões técnicas do produto e sobre satisfação, sejam positivas ou negativas. Consideramos irrelevantes as mensagens que só mencionavam o nosso produtos nas '#' ou que eram opiniões pessoais que não agregavam na nossa análise."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "## Montando um Classificador Naive-Bayes\n",
    "\n",
    "Considerando apenas as mensagens da planilha Treinamento, ensine  seu classificador."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#função que apaga os caracteres especiais e as menções de usuários\n",
    "# https://docs.python.org/3/library/re.html#\n",
    "import re \n",
    "\n",
    "\n",
    "def cleanup(text):\n",
    "    \"\"\"\n",
    "        Função de limpeza muito simples que troca alguns sinais básicos por espaços\n",
    "    \"\"\"\n",
    "    #import string\n",
    "    punctuation = '[!-.:?;[]]' # Note que os sinais [] são delimitadores de um conjunto.\n",
    "    pattern = re.compile(punctuation)\n",
    "    text_subbed = re.sub(pattern, '', text)\n",
    "    \n",
    "    #filtro que remove as menções à usuários com @\n",
    "    filtro = filter(lambda x:x[0]!='@', text_subbed.split())\n",
    "    juncao = \" \".join(filter(lambda x:x[0]!='@', text_subbed.split()))\n",
    "    \n",
    "    return juncao\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#aplicando a função cleanup na base treinamento e deixando tudo em letra minúscula\n",
    "train['Treinamento'] = train['Treinamento'].apply(cleanup)\n",
    "train['Treinamento'] = train['Treinamento'].str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      Muito irrelevante\n",
       "1        Muito relevante\n",
       "2                 Neutro\n",
       "3      Muito irrelevante\n",
       "4      Muito irrelevante\n",
       "             ...        \n",
       "746          Irrelevante\n",
       "747          Irrelevante\n",
       "748               Neutro\n",
       "749    Muito irrelevante\n",
       "750          Irrelevante\n",
       "Name: Relevância, Length: 751, dtype: category\n",
       "Categories (5, object): [Muito irrelevante < Irrelevante < Neutro < Relevante < Muito relevante]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train['Relevância'] = train['Relevância'].astype('category')\n",
    "train['Relevância'].cat.categories = ['Muito irrelevante', 'Irrelevante', 'Neutro', 'Relevante', 'Muito relevante']\n",
    "train['Relevância'].cat.as_ordered()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Criando os filtros para criar os dataFrames por relevância"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ligando a relevância à um número\n",
    "muito_relevante = train['Relevância'] == 'Muito relevante'\n",
    "relevante = train['Relevância'] == 'Relevante'\n",
    "neutro = train['Relevância'] == 'Neutro'\n",
    "irrelevante = train['Relevância'] == 'Irrelevante'\n",
    "muito_irrelevante = train['Relevância'] == 'Muito irrelevante'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Criando os dataFrames separados por relevância"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_muito_relevante = train.loc[muito_relevante, :]\n",
    "df_relevante = train.loc[relevante, :]\n",
    "df_neutro = train.loc[neutro, :]\n",
    "df_irrelevante = train.loc[irrelevante, :]\n",
    "df_muito_irrelevante = train.loc[muito_irrelevante, :]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Separando cada dataFrame da sua respectiva relevância em listas de palavras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets_muito_relevantes = []\n",
    "lista_vrw = []\n",
    "for vrw in df_muito_relevante['Treinamento']:\n",
    "    tweets_muito_relevantes.append(vrw.split(' '))\n",
    "for vrl in tweets_muito_relevantes:\n",
    "    lista_vrw += vrl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets_relevantes = []\n",
    "lista_rw = []\n",
    "for rw in df_relevante['Treinamento']:\n",
    "    tweets_relevantes.append(rw.split(' '))\n",
    "for rl in tweets_relevantes:\n",
    "    lista_rw += rl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets_neutros = []\n",
    "lista_nw = []\n",
    "for nw in df_neutro['Treinamento']:\n",
    "    tweets_neutros.append(nw.split(' '))\n",
    "for nl in tweets_neutros:\n",
    "    lista_nw += nl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets_irrelevantes = []\n",
    "lista_iw = []\n",
    "for iw in df_irrelevante['Treinamento']:\n",
    "    tweets_irrelevantes.append(iw.split(' '))\n",
    "for il in tweets_irrelevantes:\n",
    "    lista_iw += il"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets_muito_irrelevantes = []\n",
    "lista_viw = []\n",
    "for viw in df_muito_irrelevante['Treinamento']:\n",
    "    tweets_muito_irrelevantes.append(viw.split(' '))\n",
    "for vil in tweets_muito_irrelevantes:\n",
    "    lista_viw += vil"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transformando as listas de palavras de cada relevância em pd.Series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "serie_muito_relevante = pd.Series(lista_vrw)\n",
    "serie_relevante = pd.Series(lista_rw)\n",
    "serie_neutro = pd.Series(lista_nw)\n",
    "serie_irrelevante = pd.Series(lista_iw)\n",
    "serie_muito_irrelevante = pd.Series(lista_viw)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Definindo a quantidade total de palavras na língua portuguesa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nport = pd.Series(total_train)\\nprob_port = port.value_counts(True) + (alpha/lingua_portuguesa)'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#total_train são as palavras existentes nos tweets de treinamento, nos quais verificaremos\n",
    "#a freq relativa e somaremos um alpha (que representa que a palavra apareceu uma vez) pra garantir\n",
    "#que as palavras que não existem nos tweets classificados não zerem o classificador\n",
    "#total_train = lista_vrw + lista_rw + lista_nw + lista_iw + lista_viw\n",
    "\n",
    "#na fórmula precisamos dividir pela quantidade de palavras existentes na lingua portuguesa\n",
    "#para obter esse valor somamos a quantidade de palavras existentes nos tweets classificados \n",
    "#com um \"chute\" das palavras existentes que não estão em nenhum tweet classificado\n",
    "alpha = 1\n",
    "v = 1e6\n",
    "#lingua_portuguesa = len(total_train) + alpha*v\n",
    "\n",
    "'''\n",
    "port = pd.Series(total_train)\n",
    "prob_port = port.value_counts(True) + (alpha/lingua_portuguesa)'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pd.series das palavras que aparecem nos tweets classificados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'serie_total_train = pd.Series(total_train)\\n#serie_total_train.value_counts()'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''serie_total_train = pd.Series(total_train)\n",
    "#serie_total_train.value_counts()'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Frequências relativas e absolutas das palavras de cada relevância"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "o            0.000047\n",
       "ps4          0.000036\n",
       "e            0.000034\n",
       "que          0.000031\n",
       "do           0.000028\n",
       "               ...   \n",
       "microsoft    0.000002\n",
       "contrário    0.000002\n",
       "sony         0.000002\n",
       "cabo         0.000002\n",
       "será         0.000002\n",
       "Length: 557, dtype: float64"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#muito relevante\n",
    "freq_ab_mr = serie_muito_relevante.value_counts() \n",
    "freq_re_mr = (freq_ab_mr + alpha)/(freq_ab_mr.sum() + (alpha*v))\n",
    "freq_re_mr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "o             0.000115\n",
       "ps4           0.000106\n",
       "que           0.000075\n",
       "de            0.000073\n",
       "e             0.000068\n",
       "                ...   \n",
       "saio          0.000002\n",
       "trident..     0.000002\n",
       "superior.     0.000002\n",
       "lembrando     0.000002\n",
       "caladinhos    0.000002\n",
       "Length: 1211, dtype: float64"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#relevante\n",
    "freq_ab_r = serie_relevante.value_counts() \n",
    "freq_re_r = (freq_ab_r + alpha)/(freq_ab_r.sum() + (alpha*v))\n",
    "freq_re_r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#neutro\n",
    "freq_ab_n = serie_neutro.value_counts() \n",
    "freq_re_n = (freq_ab_n + alpha)/(freq_ab_n.sum() + (alpha*v))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#irrelevante\n",
    "freq_ab_i = serie_irrelevante.value_counts() \n",
    "freq_re_i = (freq_ab_i + alpha)/(freq_ab_i.sum() + (alpha*v))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#muito irrelevante\n",
    "freq_ab_mi = serie_muito_relevante.value_counts() \n",
    "freq_re_mi = (freq_ab_mi + alpha)/(freq_ab_mi.sum() + (alpha*v))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Montando Naive-Bayes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Probabilidade de cada relevância à priori"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9986684420772303\n"
     ]
    }
   ],
   "source": [
    "#contagem de tweets\n",
    "p_mr = len(tweets_muito_relevantes) / len(train[\"Treinamento\"])\n",
    "p_r = len(tweets_relevantes) / len(train[\"Treinamento\"])\n",
    "p_n = len(tweets_neutros) / len(train[\"Treinamento\"])\n",
    "p_i = len(tweets_irrelevantes) / len(train[\"Treinamento\"])\n",
    "p_mi = len(tweets_muito_irrelevantes) / len(train[\"Treinamento\"])\n",
    "\n",
    "print(p_mr + p_r + p_n + p_i + p_mi)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Função que retorna a probabilidade de uma frase pertencer à uma cateogria específica de relevância com base nas palavras que a compõem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def datawitter(frase):\n",
    "    \n",
    "    prob_frase_dado_mr = 1\n",
    "    prob_frase_dado_r = 1\n",
    "    prob_frase_dado_n = 1\n",
    "    prob_frase_dado_i = 1\n",
    "    prob_frase_dado_mi = 1\n",
    "    \n",
    "    frase = frase.split(' ')\n",
    "    \n",
    "    for palavra in frase:\n",
    "        \n",
    "        if palavra in freq_re_mr:\n",
    "            prob_frase_dado_mr *= freq_re_mr[palavra]\n",
    "        elif palavra not in freq_re_mr:\n",
    "            prob_frase_dado_mr *= (alpha/(freq_ab_mr.sum() + alpha*v))\n",
    "            \n",
    "        if palavra in freq_re_r:\n",
    "            prob_frase_dado_r *= freq_re_r[palavra]\n",
    "        elif palavra not in freq_re_r:\n",
    "            prob_frase_dado_r *= (alpha/(freq_ab_r.sum() + alpha*v))\n",
    "            \n",
    "        if palavra in freq_re_n:\n",
    "            prob_frase_dado_n *= freq_re_n[palavra]\n",
    "        elif palavra not in freq_re_n:\n",
    "            prob_frase_dado_n *= (alpha/(freq_ab_n.sum() + alpha*v))\n",
    "            \n",
    "        if palavra in freq_re_i:\n",
    "            prob_frase_dado_i *= freq_re_i[palavra]\n",
    "        elif palavra not in freq_re_i:\n",
    "            prob_frase_dado_i *= (alpha/(freq_ab_i.sum() + alpha*v))\n",
    "            \n",
    "        if palavra in freq_re_mi:\n",
    "            prob_frase_dado_mi *= freq_re_mi[palavra]\n",
    "        elif palavra not in freq_re_mi:\n",
    "            prob_frase_dado_mi *= (alpha/(freq_ab_mi.sum() + alpha*v))\n",
    "            \n",
    "      #soma de contagens naquela cat  \n",
    "    prob_mr_dado_frase = prob_frase_dado_mr*p_mr\n",
    "    prob_r_dado_frase = prob_frase_dado_r*p_r\n",
    "    prob_n_dado_frase = prob_frase_dado_n*p_n\n",
    "    prob_i_dado_frase = prob_frase_dado_i*p_i\n",
    "    prob_mi_dado_frase = prob_frase_dado_mi*p_mi\n",
    "    \n",
    "    if max(prob_mr_dado_frase, prob_r_dado_frase, prob_n_dado_frase, prob_i_dado_frase, prob_mi_dado_frase) == prob_mr_dado_frase:\n",
    "        return 'Muito relevante'\n",
    "    if max(prob_mr_dado_frase, prob_r_dado_frase, prob_n_dado_frase, prob_i_dado_frase, prob_mi_dado_frase) == prob_r_dado_frase:\n",
    "        return 'Relevante'\n",
    "    if max(prob_mr_dado_frase, prob_r_dado_frase, prob_n_dado_frase, prob_i_dado_frase, prob_mi_dado_frase) == prob_n_dado_frase:\n",
    "        return 'Neutro'\n",
    "    if max(prob_mr_dado_frase, prob_r_dado_frase, prob_n_dado_frase, prob_i_dado_frase, prob_mi_dado_frase) == prob_i_dado_frase:\n",
    "        return 'Irrelevante'\n",
    "    if max(prob_mr_dado_frase, prob_r_dado_frase, prob_n_dado_frase, prob_i_dado_frase, prob_mi_dado_frase) == prob_mi_dado_frase:\n",
    "        return 'Muito irrelevante'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Coluna do dataFrame que contem a nossa classificação"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "#del train['Classificacao']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['Classificacao'] = ''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preenchimento da coluna contendo a nossa classificação"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-31-4cdc29e04c33>:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  train['Classificacao'][(train[train['Treinamento']==frase].index.values)] = datawitter(frase)\n"
     ]
    }
   ],
   "source": [
    "for frase in train['Treinamento']:\n",
    "    train['Classificacao'][(train[train['Treinamento']==frase].index.values)] = datawitter(frase)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train[\"Classificacao\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['Classificacao'] = train['Classificacao'].astype('category')\n",
    "train['Classificacao'].cat.categories = ['Muito irrelevante', 'Irrelevante', 'Neutro', 'Relevante', 'Muito relevante']\n",
    "train['Classificacao'].cat.as_ordered()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Irrelevante    470\n",
       "Relevante      101\n",
       "Neutro         180\n",
       "Name: Classificacao, dtype: int64"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train['Classificacao'].value_counts(sort=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tabela que retorna a eficácia do nosso classificador"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tabela = pd.crosstab(train['Relevância'], train['Classificacao'], normalize='all')\n",
    "tabela"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Eficácia do nosso classificador"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#quanto o classificador acertou?\n",
    "f'{(tabela.iloc[0,0]+tabela.iloc[1,1]+tabela.iloc[2,2]+tabela.iloc[3,3]+tabela.iloc[4,4])*100:.5g}%'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "### Verificando a performance do Classificador\n",
    "\n",
    "Agora você deve testar o seu classificador com a base de Testes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transformando o dataFrame teste em string para poder aplicar a função cleanup e deixar o texto todo em minúscula"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = pd.read_excel(filename, sheet_name = 'Teste')\n",
    "test['Teste'] = test['Teste'].astype('str')\n",
    "test['Teste'] = test['Teste'].apply(cleanup)\n",
    "test['Teste'] = test['Teste'].str.lower()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transformando a coluna 'Relevância' em categórica"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test['Relevância'] = test['Relevância'].astype('category')\n",
    "test['Relevância'].cat.categories = ['Muito irrelevante', 'Irrelevante', 'Neutro', 'Relevante', 'Muito relevante']\n",
    "test['Relevância'].cat.as_ordered()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preenchendo a coluna que contêm as classificações do nosso classificador"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test['Classificador'] = ''\n",
    "for frase in test['Teste']:\n",
    "    test['Classificador'][(test[test['Teste']==frase].index.values)] = datawitter(frase)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test['Classificador'].cat.as_ordered()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tabela2 = pd.crosstab(test['Relevância'], test['Classificador'], normalize='all')\n",
    "tabela2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#quanto o classificador acertou?\n",
    "\n",
    "f'{(tabela2.iloc[0,0]+tabela2.iloc[1,1]+tabela2.iloc[2,2]+tabela2.iloc[3,3]+tabela2.iloc[4,4])*100:.5g}%'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "### Concluindo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "## Aperfeiçoamento:\n",
    "\n",
    "Os trabalhos vão evoluir em conceito dependendo da quantidade de itens avançados:\n",
    "\n",
    "* Limpar: \\n, :, \", ', (, ), etc SEM remover emojis\n",
    "* Corrigir separação de espaços entre palavras e emojis ou entre emojis e emojis\n",
    "* Propor outras limpezas e transformações que não afetem a qualidade da informação ou classificação\n",
    "* Criar categorias intermediárias de relevância baseadas na probabilidade: ex.: muito relevante, relevante, neutro, irrelevante, muito irrelevante (3 categorias: C, mais categorias conta para B)\n",
    "* Explicar por que não posso usar o próprio classificador para gerar mais amostras de treinamento\n",
    "* Propor diferentes cenários para Naïve Bayes fora do contexto do projeto\n",
    "* Sugerir e explicar melhorias reais com indicações concretas de como implementar (indicar como fazer e indicar material de pesquisa)\n",
    "* Montar um dashboard que realiza análise de sentimento e visualiza estes dados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "## Referências"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Naive Bayes and Text Classification](https://arxiv.org/pdf/1410.5329.pdf)  **Mais completo**\n",
    "\n",
    "[A practical explanation of a Naive Bayes Classifier](https://monkeylearn.com/blog/practical-explanation-naive-bayes-classifier/) **Mais simples**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
