{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Projeto 1 - Ci√™ncia dos Dados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nome: Raphael Lahiry de Barros\n",
    "\n",
    "Nome: Florencia Averame Kramer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# O que temos que fazer?\n",
    "precisamos criar um dataframe para cada relev√¢ncia   OK\n",
    "\n",
    "dentro desses dataframes separar as frases em palavras OK   \n",
    "\n",
    "analisar a freq relativa de cada palavra --> probabilidade daquela palavra pertencer √†quela relev√¢ncia    \n",
    "\n",
    "quando quisermos avaliar o teste--> analisamos a probabilidade de cada palavra de uma frase pertencer a uma relev√¢ncia (usar o smoothing -- aula 8 -- para as palavras que talvez n√£o existam em certas categorias)  \n",
    "\n",
    "com isso, para cada palavra teremos a probabilidade de que esta perten√ßa a cada relev√¢ncia  \n",
    "a relev√¢ncia com maior probabilidade ser√° a daquela palavra"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Aten√ß√£o:** Ser√£o permitidos grupos de tr√™s pessoas, mas com uma rubrica mais exigente. Grupos deste tamanho precisar√£o fazer um question√°rio de avalia√ß√£o de trabalho em equipe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "## Carregando algumas bibliotecas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Em `filename`, coloque o nome do seu arquivo de dados!**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encontrei o arquivo ps4.xlsx, tudo certo para prosseguir com a prova!\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "filename = 'ps4.xlsx'\n",
    "if filename in os.listdir():\n",
    "    print(f'Encontrei o arquivo {filename}, tudo certo para prosseguir com a prova!')\n",
    "else:\n",
    "    print(f'N√£o encontrei o arquivo {filename} aqui no diret√≥rio {os.getcwd()}, ser√° que voc√™ n√£o baixou o arquivo?')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Carregando a base de dados com os tweets classificados como relevantes e n√£o relevantes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Treinamento</th>\n",
       "      <th>Relev√¢ncia</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>@odonodocabare_ comprei um tablet dia desses e...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>@encanadorchapad o neg√≥cio √© o ps4 slim. peque...</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>rt @ps3brasil: tohu √© anunciado para ps4; deta...</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>dividindo essa semana entre dois jogos no modo...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>@leobruto @fridaygus @douglasxavier8 @ocerveje...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         Treinamento  Relev√¢ncia\n",
       "0  @odonodocabare_ comprei um tablet dia desses e...         0.0\n",
       "1  @encanadorchapad o neg√≥cio √© o ps4 slim. peque...         4.0\n",
       "2  rt @ps3brasil: tohu √© anunciado para ps4; deta...         2.0\n",
       "3  dividindo essa semana entre dois jogos no modo...         0.0\n",
       "4  @leobruto @fridaygus @douglasxavier8 @ocerveje...         0.0"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train = pd.read_excel(filename)\n",
    "train.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['Treinamento'] = train['Treinamento'].astype('str')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Teste</th>\n",
       "      <th>Relev√¢ncia</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>@chaehobbit simmm sou apaixonada em jogos assi...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>@pimps_junin @joao_almirante atleta nato , pod...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>@isa_boechatt kkkk vc joga onde no xbox ps4 ou...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>@vezguu eu sou ps4</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>path of exile (ps4) - farmando e fazendo o atl...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Teste  Relev√¢ncia\n",
       "0  @chaehobbit simmm sou apaixonada em jogos assi...         1.0\n",
       "1  @pimps_junin @joao_almirante atleta nato , pod...         1.0\n",
       "2  @isa_boechatt kkkk vc joga onde no xbox ps4 ou...         1.0\n",
       "3                                 @vezguu eu sou ps4         1.0\n",
       "4  path of exile (ps4) - farmando e fazendo o atl...         0.0"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = pd.read_excel(filename, sheet_name = 'Teste')\n",
    "test.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "test['Teste'] = test['Teste'].astype('str')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "## Classificador autom√°tico de sentimento\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fa√ßa aqui uma descri√ß√£o do seu produto e o que considerou como relevante ou n√£o relevante na classifica√ß√£o dos tweets.\n",
    "\n",
    "Nosso produto √© o playstation 4. Consideramos relevantes as mensagens que falavam sobre quest√µes t√©cnicas do produto e sobre satisfa√ß√£o, sejam positivas ou negativas. Consideramos irrelevantes as mensagens que s√≥ mencionavam o nosso produtos nas '#' ou que eram opini√µes pessoais que n√£o agregavam na nossa an√°lise."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "## Montando um Classificador Naive-Bayes\n",
    "\n",
    "Considerando apenas as mensagens da planilha Treinamento, ensine  seu classificador."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "#fun√ß√£o que apaga os caracteres especiais e as men√ß√µes de usu√°rios\n",
    "# https://docs.python.org/3/library/re.html#\n",
    "import re \n",
    "\n",
    "\n",
    "def cleanup(text):\n",
    "    \"\"\"\n",
    "        Fun√ß√£o de limpeza muito simples que troca alguns sinais b√°sicos por espa√ßos\n",
    "    \"\"\"\n",
    "    #import string\n",
    "    punctuation = '[!-.:?;[]]' # Note que os sinais [] s√£o delimitadores de um conjunto.\n",
    "    pattern = re.compile(punctuation)\n",
    "    text_subbed = re.sub(pattern, '', text)\n",
    "    \n",
    "    #filtro que remove as men√ß√µes √† usu√°rios com @\n",
    "    filtro = filter(lambda x:x[0]!='@', text_subbed.split())\n",
    "    juncao = \" \".join(filter(lambda x:x[0]!='@', text_subbed.split()))\n",
    "    \n",
    "    return juncao\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "#aplicando a fun√ß√£o cleanup na base treinamento e deixando tudo em letra min√∫scula\n",
    "train['Treinamento'] = train['Treinamento'].apply(cleanup)\n",
    "train['Treinamento'] = train['Treinamento'].str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ligando a relev√¢ncia √† um n√∫mero\n",
    "muito_relevante = train['Relev√¢ncia'] == 4\n",
    "relevante = train['Relev√¢ncia'] == 3\n",
    "neutro = train['Relev√¢ncia'] == 2\n",
    "irrelevante = train['Relev√¢ncia'] == 1\n",
    "muito_irrelevante = train['Relev√¢ncia'] == 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Treinamento</th>\n",
       "      <th>Relev√¢ncia</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>comprei um tablet dia desses e to bem feliz......</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>o neg√≥cio √© o ps4 slim. pequeno e silencioso, ...</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>rt tohu √© anunciado para ps4; detalhes e gamep...</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>dividindo essa semana entre dois jogos no modo...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>sentiu ? kkkkk. s√≥ fiz uma pergunta bem simple...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         Treinamento  Relev√¢ncia\n",
       "0  comprei um tablet dia desses e to bem feliz......         0.0\n",
       "1  o neg√≥cio √© o ps4 slim. pequeno e silencioso, ...         4.0\n",
       "2  rt tohu √© anunciado para ps4; detalhes e gamep...         2.0\n",
       "3  dividindo essa semana entre dois jogos no modo...         0.0\n",
       "4  sentiu ? kkkkk. s√≥ fiz uma pergunta bem simple...         0.0"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Filtros para criar os dataFrames com cada relev√¢ncia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_muito_relevante = train.loc[muito_relevante, :]\n",
    "df_relevante = train.loc[relevante, :]\n",
    "df_neutro = train.loc[neutro, :]\n",
    "df_irrelevante = train.loc[irrelevante, :]\n",
    "df_muito_irrelevante = train.loc[muito_irrelevante, :]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Separando cada coluna de relev√¢ncia em listas de palavras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "palavras_muito_relevantes = []\n",
    "lista_vrw = []\n",
    "for vrw in df_muito_relevante['Treinamento']:\n",
    "    palavras_muito_relevantes.append(vrw.split(' '))\n",
    "for vrl in palavras_muito_relevantes:\n",
    "    lista_vrw += vrl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "palavras_relevantes = []\n",
    "lista_rw = []\n",
    "for rw in df_relevante['Treinamento']:\n",
    "    palavras_relevantes.append(rw.split(' '))\n",
    "for rl in palavras_relevantes:\n",
    "    lista_rw += rl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "palavras_neutras = []\n",
    "lista_nw = []\n",
    "for nw in df_neutro['Treinamento']:\n",
    "    palavras_neutras.append(nw.split(' '))\n",
    "for nl in palavras_neutras:\n",
    "    lista_nw += nl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "palavras_irrelevantes = []\n",
    "lista_iw = []\n",
    "for iw in df_irrelevante['Treinamento']:\n",
    "    palavras_irrelevantes.append(iw.split(' '))\n",
    "for il in palavras_irrelevantes:\n",
    "    lista_iw += il"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "palavras_muito_irrelevantes = []\n",
    "lista_viw = []\n",
    "for viw in df_muito_irrelevante['Treinamento']:\n",
    "    palavras_muito_irrelevantes.append(viw.split(' '))\n",
    "for vil in palavras_muito_irrelevantes:\n",
    "    lista_viw += vil"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transformando as listas de palavras de cada relev√¢ncia em pd.Series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "serie_muito_relevante = pd.Series(lista_vrw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "serie_relevante = pd.Series(lista_rw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "serie_neutro = pd.Series(lista_nw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "serie_irrelevante = pd.Series(lista_iw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "serie_muito_irrelevante = pd.Series(lista_viw)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Frequ√™ncias relativas e absolutas das palavras de cada relev√¢ncia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "freq_ab_muito_relevante = serie_muito_relevante.value_counts()\n",
    "freq_re_muito_relevante = serie_muito_relevante.value_counts(True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "freq_ab_relevante = serie_relevante.value_counts()\n",
    "freq_re_relevante = serie_relevante.value_counts(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "freq_ab_neutro = serie_neutro.value_counts()\n",
    "freq_re_neutro = serie_neutro.value_counts(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "freq_ab_irrelevante = serie_irrelevante.value_counts()\n",
    "freq_re_irrelevante = serie_irrelevante.value_counts(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "freq_ab_muito_irrelevante = serie_muito_irrelevante.value_counts()\n",
    "freq_re_muito_irrelevante = serie_muito_irrelevante.value_counts(True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Definindo a quantidade total de palavras na l√≠ngua portuguesa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "#portugues s√£o as palavras existes que a gente vai verificar a freq relativa e vamos somar um alpha pra garantir\n",
    "#que as palavras que n√£o existem n√£o zerem o classificador\n",
    "portugues = lista_vrw + lista_rw + lista_nw + lista_iw + lista_viw\n",
    "\n",
    "#na f√≥rmula precisamos dividir pela quantidade de palavras na lingua portuguesa\n",
    "alpha = 1\n",
    "v = 1e6\n",
    "lingua_portuguesa = len(lista_vrw) + len(lista_rw) + len(lista_nw) + len(lista_iw) + len(lista_viw) + alpha*v"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pd.series do portugu√™s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ps4           545\n",
       "o             463\n",
       "de            369\n",
       "e             359\n",
       "no            274\n",
       "             ... \n",
       "frictional      1\n",
       "ü•∫ü•∫ü•∫ü•∫            1\n",
       "baixo           1\n",
       "produzindo      1\n",
       "saia            1\n",
       "Length: 4270, dtype: int64"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "serie_portugues = pd.Series(portugues)\n",
    "serie_portugues.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Criando a probabilidade de cada relev√¢ncia √† priori"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n"
     ]
    }
   ],
   "source": [
    "p_mr = len(serie_muito_relevante)/len(serie_portugues)\n",
    "p_r = len(serie_relevante)/len(serie_portugues)\n",
    "p_n = len(serie_neutro)/len(serie_portugues)\n",
    "p_i = len(serie_irrelevante)/len(serie_portugues)\n",
    "p_mi = len(serie_muito_irrelevante)/len(serie_portugues)\n",
    "\n",
    "print(p_mr + p_r + p_n + p_i + p_mi)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Montando Naive-Bayes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classificador da relev√¢ncia de cada palavra"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lista muito relevante\n",
    "dict_relevancia_palavras = {}\n",
    "\n",
    "\n",
    "for palavra in portugues:\n",
    "    if (palavra not in lista_vrw) and (palavra not in lista_rw) and (palavra not in lista_nw) and (palavra not in lista_iw) and (palavra not in lista_viw):\n",
    "        mr = alpha/len(portugues)\n",
    "        r = alpha/len(portugues)\n",
    "        n = alpha/len(portugues)\n",
    "        i = alpha/len(portugues)\n",
    "        mi = alpha/len(portugues)\n",
    "        \n",
    "    if palavra in lista_vrw:\n",
    "        mr = freq_re_muito_relevante[palavra] \n",
    "    \n",
    "       \n",
    "    if palavra in lista_rw:\n",
    "        r = freq_re_relevante[palavra] \n",
    "       \n",
    "    if palavra in lista_nw:\n",
    "        n = freq_re_neutro[palavra] \n",
    "        \n",
    "    if palavra in lista_iw:\n",
    "        i = freq_re_irrelevante[palavra] \n",
    "       \n",
    "    if palavra in lista_viw:\n",
    "        mi = freq_re_muito_irrelevante[palavra] \n",
    "     \n",
    "    if (mr > r) and (mr > n) and (mr > i) and (mr > mi):\n",
    "        #print('mr')\n",
    "        dict_relevancia_palavras[palavra] = 4\n",
    "        #break\n",
    "    elif (r > mr) and (r > n) and (r > i) and (r > mi):\n",
    "        #print('r')\n",
    "        dict_relevancia_palavras[palavra] = 3\n",
    "        #break\n",
    "    elif (n > mr) and (n > r) and (n > i) and (n > mi):\n",
    "        #print('n')\n",
    "        dict_relevancia_palavras[palavra] = 2\n",
    "        #break\n",
    "    elif (i > mr) and (i > r) and (i > n) and (i > mi):\n",
    "        #print('i')\n",
    "        dict_relevancia_palavras[palavra] = 1\n",
    "        #break\n",
    "    elif (mi > mr) and (mi > r) and (mi > n) and (mi > i):\n",
    "        #print('mi')\n",
    "        dict_relevancia_palavras[palavra] = 0\n",
    "        #break\n",
    "    \n",
    "#dict_relevancia_palavras"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "### Verificando a performance do Classificador\n",
    "\n",
    "Agora voc√™ deve testar o seu classificador com a base de Testes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "test['Teste'] = test['Teste'].apply(cleanup)\n",
    "test['Teste'] = test['Teste'].str.lower()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "### Concluindo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "## Aperfei√ßoamento:\n",
    "\n",
    "Os trabalhos v√£o evoluir em conceito dependendo da quantidade de itens avan√ßados:\n",
    "\n",
    "* Limpar: \\n, :, \", ', (, ), etc SEM remover emojis\n",
    "* Corrigir separa√ß√£o de espa√ßos entre palavras e emojis ou entre emojis e emojis\n",
    "* Propor outras limpezas e transforma√ß√µes que n√£o afetem a qualidade da informa√ß√£o ou classifica√ß√£o\n",
    "* Criar categorias intermedi√°rias de relev√¢ncia baseadas na probabilidade: ex.: muito relevante, relevante, neutro, irrelevante, muito irrelevante (3 categorias: C, mais categorias conta para B)\n",
    "* Explicar por que n√£o posso usar o pr√≥prio classificador para gerar mais amostras de treinamento\n",
    "* Propor diferentes cen√°rios para Na√Øve Bayes fora do contexto do projeto\n",
    "* Sugerir e explicar melhorias reais com indica√ß√µes concretas de como implementar (indicar como fazer e indicar material de pesquisa)\n",
    "* Montar um dashboard que realiza an√°lise de sentimento e visualiza estes dados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "## Refer√™ncias"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Naive Bayes and Text Classification](https://arxiv.org/pdf/1410.5329.pdf)  **Mais completo**\n",
    "\n",
    "[A practical explanation of a Naive Bayes Classifier](https://monkeylearn.com/blog/practical-explanation-naive-bayes-classifier/) **Mais simples**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
